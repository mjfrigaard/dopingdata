---
title: "Scraping USADA prohibited associations"
output: 
  rmarkdown::html_vignette:
    df_print: kable
vignette: >
  %\VignetteIndexEntry{Scraping USADA prohibited associations}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(
  pillar.print_max = 25, 
  dplyr.print_max = 25,
  knitr.kable.NA = '',
  pillar.print_min = 25)

library(dopingdata)
library(dplyr)
library(tidyr)
library(stringr)
library(forcats)
library(lubridate)
library(readr)
library(readxl)
library(janitor)
library(anytime)
library(robotstxt)
options(robotstxt_warn = FALSE)
```

Packages:

```{r pkg, eval=FALSE, message=FALSE, warning=FALSE}
library(dopingdata)
library(dplyr)
library(tidyr)
library(stringr)
library(forcats)
library(lubridate)
library(readr)
library(readxl)
library(janitor)
library(anytime)
library(robotstxt)
options(robotstxt_warn = FALSE)
```

## USADA prohibited association data

The data I'll be downloading comes from [USADA prohibited association  table](https://www.usada.org/news/prohibited-association/).

## Use your manners 

Because this package is built on top of the efforts of the fine people who collected, organized, and shared their data, we're going to use the [`polite` package](https://dmi3kno.github.io/polite/) for harvesting the HTML tables. 

To install this package, run the code below: 

```{r inst-polite, eval=FALSE}
remotes::install_github("dmi3kno/polite")
library(polite)
```

`polite` has many options for ethically scraping data (check out the [package website](https://dmi3kno.github.io/polite/reference/index.html) for more information), but I've chosen to follow the handy [polite template](https://dmi3kno.github.io/polite/#polite-template):

```{r use_manners, eval=FALSE}
polite::use_manners()
```

### Check `robots.txt`

I'll check the `robots.txt` file before scraping the website:

```{r rt}
# retrieval
rtxt <- robotstxt::robotstxt(domain = "https://www.usada.org/")

# printing
rtxt$check(
  paths = c("news/", 
            "news/prohibited-association/"),
  bot   = "*"
)
```

Both paths are `TRUE`.

I'll also check the domain with `robotstxt::get_robotstxt()`:

```{r get_robotstxt}
rt <- robotstxt::get_robotstxt(
  domain = "https://www.usada.org/news/prohibited-association/")
# printing
cat(rt[1])
```

I can see the `Allow: /` configuration [gives us access to download](https://kinsta.com/blog/wordpress-robots-txt/#how-to-use-robotstxt-allow-all-to-give-robots-full-access-to-your-site) the data. 


### Scraping with `polite` and `rvest`

Below are the steps used to scrape the prohibited associations table:

```{r scrape, eval=FALSE, include=FALSE, echo=FALSE}
usada_path = "https://www.usada.org/news/prohibited-association/"
# extract html
usada_extraction <- rvest::read_html(usada_path)
# nodes
usada_nodes <- rvest::html_nodes(usada_extraction, "table")
# raw data
usada_prohib_assoc_raw <- rvest::html_table(usada_nodes[[1]]) |> 
                    tibble::as_tibble()
```

```{r polite-scraping, eval=FALSE}
usada_url = "https://www.usada.org/news/prohibited-association/"
usada_nodes <- polite::bow(usada_url) |> 
  polite::scrape() |> 
  rvest::html_nodes("table") 
usada_prohib_assoc_raw <- rvest::html_table(usada_nodes[[1]])
```


```{r import-usada_prohib_assoc_raw, message=FALSE, warning=FALSE, echo=FALSE, results='hide'}
usada_prohib_assoc_raw <- readr::read_rds(
  file = "../inst/extdata/raw/2023-01-19/2023-01-19-usada_prohib_assoc_raw.rds")
```

```{r usada_prohib_assoc_raw}
dplyr::glimpse(usada_prohib_assoc_raw)
```

## Process text 

The `process_text()` function will lowercase the all the text in the dataset. It also applies `janitor::clean_names()` to the column names:

```{r usada_prohib_assoc_pro}
usada_prohib_assoc_pro <- process_text(usada_prohib_assoc_raw)
dplyr::glimpse(usada_prohib_assoc_pro)
```

### Column names 

We can change the name of `suspension_ends_mm_dd_yyyy` to `suspend_end`:

```{r usada_prohib_assoc_cols}
dplyr::rename(usada_prohib_assoc_pro, 
  suspend_end = suspension_ends_mm_dd_yyyy)
```

### `suspend_type` 

Create an indicator variable (`suspend_type`) for three categories of  suspensions: `temporary`, `lifetime` or `indefinite*`

```{r suspend_type}
dplyr::rename(usada_prohib_assoc_pro, 
  suspend_end = suspension_ends_mm_dd_yyyy) |> 
  dplyr::mutate(
    suspend_type = dplyr::case_when(
      stringr::str_detect(suspend_end, "lifetime") ~ "lifetime",
      stringr::str_detect(suspend_end, "indefinite*") ~ "indefinite*",
      TRUE ~ "temporary"))
```

### `suspend_end` 

The `suspend_end` contains dates and represent the date the suspension ends. 

```{r dates-suspend_end}
dplyr::rename(usada_prohib_assoc_pro, 
  suspend_end = suspension_ends_mm_dd_yyyy) |> 
  dplyr::mutate(
    suspend_type = dplyr::case_when(
      stringr::str_detect(suspend_end, "lifetime") ~ "lifetime",
      stringr::str_detect(suspend_end, "indefinite*") ~ "indefinite*",
      TRUE ~ "temporary"),
    suspend_end = dplyr::case_when(
      stringr::str_detect(suspend_end, "lifetime|indefinite*") ~ NA_character_,
      TRUE ~ suspend_end),
    suspend_end = lubridate::mdy(suspend_end))
```

## `usada_proh_assoc`

The resulting dataset will be named `usada_proh_assoc` and exported to `inst/extdata/pro/`

```{r usada_proh_assoc}
usada_proh_assoc <- dplyr::rename(usada_prohib_assoc_pro, 
  suspend_end = suspension_ends_mm_dd_yyyy) |> 
  dplyr::mutate(suspend_type = dplyr::case_when(
      stringr::str_detect(suspend_end, "lifetime") ~ "lifetime",
      stringr::str_detect(suspend_end, "indefinite*") ~ "indefinite*",
      TRUE ~ "temporary"),
    suspend_end = dplyr::case_when(
      stringr::str_detect(suspend_end, "lifetime|indefinite*") ~ NA_character_,
      TRUE ~ suspend_end),
    suspend_end = lubridate::mdy(suspend_end))
dplyr::glimpse(usada_proh_assoc)
```

## Export raw data 

I'll export the raw data into the `inst/extdata/raw/` folder. First create a raw data folder for today's data:

``` r
create_dir_date(dir_path = "../inst/extdata/", dir_name = "raw/")
✔ Creating folder: ../inst/extdata/raw/2023-01-20/
✔ path is on clipboard!
```

Create the file paths for .csv and .rds files. 

```{r output-csv_pth, eval=TRUE}
csv_pth <- paste0('../inst/extdata/raw/', Sys.Date(), '/', 
                  dtstamp(side = "r"), 'usada_prohib_assoc_raw.csv')
csv_pth
rds_pth <-  paste0('../inst/extdata/raw/', Sys.Date(), '/', 
                  dtstamp(side = "r"), 'usada_prohib_assoc_raw.rds')
rds_pth
```

If these look good, I can run the export functions:

```{r export-raw, eval=FALSE}
readr::write_csv(x = usada_prohib_assoc_raw, file = csv_pth)
readr::write_rds(x = usada_prohib_assoc_raw, file = rds_pth)
```

Verify: 

```{r verify}
fs::dir_tree(
  path = paste0("../inst/extdata/raw/", Sys.Date(), '/'), 
  regexp = "assoc_raw"
  )
```


## Export processed data 

I want to export the processed data into a separate folder (`inst/extdata/<today>`), which I can create using `create_dir_date()`

``` r
create_dir_date(dir_path = "../inst/extdata/", dir_name = "pro/")
✔ Creating folder: ../inst/extdata/pro/2023-01-20/
✔ path is on clipboard!
```

Create export processed paths: 

```{r processed-output-dirs, eval=TRUE}
csv_pth <- paste0('../inst/extdata/pro/',
                        Sys.Date(),
                        '/',
                        dtstamp(side = "r"),
                        'usada_proh_assoc_pro.csv')
csv_pth
rds_pth <- paste0('../inst/extdata/pro/',
                        Sys.Date(),
                        '/',
                        dtstamp(side = "r"),
                        'usada_proh_assoc_pro.rds')
rds_pth
```

```{r export-processed, eval=FALSE}
readr::write_csv(x = usada_proh_assoc, file = csv_pth)
readr::write_rds(x = usada_proh_assoc, file = rds_pth)
```

Verify: 

```{r processed-verify}
fs::dir_tree(path = paste0("../inst/extdata/pro/", Sys.Date(), '/'), 
  regexp = "assoc_pro")
```
