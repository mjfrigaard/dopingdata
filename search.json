[{"path":[]},{"path":"https://mjfrigaard.github.io/dopingdata/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement Martin Frigaard. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 Martin Frigaard Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"AAF substances sanctions","text":"vignette covers classification single substances USADA sanction data.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"data-versioning","dir":"Articles","previous_headings":"","what":"Data versioning","title":"AAF substances sanctions","text":"package uses data table gets updated regularly. keep track versions, ’ve organized inst/extdata folder date (YYYY-MM-DD), helper function getting recent version: Now can use tdy_stmp whenever need use find data version! See :","code":"tdy_stmp <- get_recent_version(\"../inst/extdata/raw\") tdy_stmp"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"outline","dir":"Articles","previous_headings":"","what":"Outline","title":"AAF substances sanctions","text":"vignette assumes following: Scrape website: copy USADA sanctions table scraped lives inst/extdata/raw/ folder See scrape_usada_sanctions() function scraping-usada.Rmd vignette information data column names formatted janitor::clean_names(), text converted lowercase Fix dates: dates table formatted wrangled See vignettes/sanction-dates.Rmd vignette information Tidy sports: sport column ‘tidied’ athletes/support personnel listed one sport repeated data See vignettes/sports.Rmd vignette information","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"data","dir":"Articles","previous_headings":"Outline","what":"Data","title":"AAF substances sanctions","text":"’ll import recent version tidy USADA sports data: data names standardized, text converted lowercase.","code":"get_recent_data_file(\"../inst/extdata/pro/\",    type = \"csv\") ✔ import code pasted to clipboard! ✔ use: readr::read_csv('../inst/extdata/pro/2023-01-20/2023-01-20-usada_sanctions_pro.csv') tidy_usada_sports <- readr::read_csv(   file = '../inst/extdata/pro/2023-01-20/2023-01-20-usada_sanctions_pro.csv') dplyr::glimpse(tidy_usada_sports)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"sanctions","dir":"Articles","previous_headings":"","what":"Sanctions","title":"AAF substances sanctions","text":"sanctions divided two categories: analytic: Adverse Analytical Finding, AAF; AAF report WADA-accredited laboratory identifies presence prohibited substance /metabolites markers sample. non-analytic: Non-Analytical Anti-doping Rule Violation ADRV; non-analytical anti-doping rule violation stem positive urine blood sample, instead originates , substantiated , evidence doping violations athlete athlete support personnel..","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"substances-vs-reasons","dir":"Articles","previous_headings":"Sanctions","what":"Substances vs Reasons","title":"AAF substances sanctions","text":"sanctions WADA data due analytic findings (Adverse Analytical Finding (AAF)), others due reasons (.e. ‘non-analytical’ ‘non-analytic’ sanctions). substance_reason column contains details sanction, can include following information: name banned substance description infraction (non-analytic) See examples :","code":"stringr::str_view_all(head(tidy_usada_sports$substance_reason, 25),    \"steroid\", match = TRUE) stringr::str_view_all(head(tidy_usada_sports$substance_reason, 10),   \"non-analytical\", match = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"sanction-type","dir":"Articles","previous_headings":"Sanctions","what":"Sanction type","title":"AAF substances sanctions","text":"non-analytic sanctions include terms non-analytic/non-analytical/etc., prefix substance_reason column. can pass terms regular expressions create sanction_type variable, contain two values: non-analytical analytical ’ll save variable usada_sanction_types dataset.","code":"usada_sanction_types <- dplyr::mutate(.data = tidy_usada_sports,     sanction_type = case_when(       str_detect(string = substance_reason,          \"non-analytical\") ~ \"non-analytical\",       !str_detect(substance_reason,          \"non-analytical\") ~ \"analytical\",       TRUE ~ NA_character_     )    ) usada_sanction_types |>    dplyr::count(sanction_type, sort = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"analytic-sanctions","dir":"Articles","previous_headings":"","what":"Analytic sanctions","title":"AAF substances sanctions","text":"Now can filter usada_sanction_types analytical sanctions sanction_type. number \"analytical\" values sanction_type.","code":"dplyr::filter(usada_sanction_types,          sanction_type == \"analytical\") |> nrow()"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"non-analytic-sanctions","dir":"Articles","previous_headings":"","what":"Non-analytic sanctions","title":"AAF substances sanctions","text":"","code":"dplyr::filter(usada_sanction_types,    sanction_type == \"non-analytical\") |>    nrow()"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"single-vs--multiple-substances","dir":"Articles","previous_headings":"","what":"Single vs. multiple substances","title":"AAF substances sanctions","text":"identify single vs. multiple substances, first ’ll identify multiple substances using regular expression, ’ll negate regular expression single substances. Now ’ll divide single multiple analytic substances:","code":"usada_substance_types <- usada_sanction_types |>    dplyr::mutate(multiple_substances = case_when(     stringr::str_detect(substance_reason, \"; |, | and | & | / \") ~ TRUE,     !stringr::str_detect(substance_reason, \"; |, | and | & | / \") ~FALSE,     TRUE ~ NA))  usada_substance_types |>    dplyr::count(multiple_substances, sort = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"multiple-analytic-substances","dir":"Articles","previous_headings":"Single vs. multiple substances","what":"Multiple analytic substances","title":"AAF substances sanctions","text":"‘count counts’, tells multiple substance combinations occur .","code":"multiple_analytic_subs <- usada_substance_types |>    dplyr::filter(multiple_substances == TRUE)   multiple_analytic_subs |>    dplyr::count(substance_reason, sort = TRUE, name = \"Count\") |>    count(Count, sort = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"single-analytic-substances","dir":"Articles","previous_headings":"Single vs. multiple substances","what":"Single analytic substances","title":"AAF substances sanctions","text":"count single analytic substances:","code":"single_analytic_subs <- usada_substance_types |>    dplyr::filter(multiple_substances == FALSE)   single_analytic_subs |>    dplyr::count(substance_reason, sort = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"classifying-substances","dir":"Articles","previous_headings":"","what":"Classifying substances","title":"AAF substances sanctions","text":"identify WADA banned substances, ’ve written classify_wada_substances(), function scans substance_reason column identifies substances found WADA list. See Appendix (bottom) information.","code":"classified_single_aaf_substance <- classify_wada_substances(   usada_data = single_analytic_subs,    subs_column = substance_reason)  classified_single_aaf_substance |>    dplyr::count(substance_group, sort = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"s1-anabolic-agents","dir":"Articles","previous_headings":"Classifying substances","what":"S1 ANABOLIC AGENTS","title":"AAF substances sanctions","text":"S1 substances : Check matches:","code":"tibble::tibble(dopingdata::s1_substances) stringr::str_view_all(string = classified_single_aaf_substance$substance_reason,    pattern = s1_regex, match = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"s2-peptide-hormones-growth-factors-related-substances-and-mimetics","dir":"Articles","previous_headings":"Classifying substances","what":"S2 PEPTIDE HORMONES, GROWTH FACTORS, RELATED SUBSTANCES, AND MIMETICS","title":"AAF substances sanctions","text":"S2 substances : Check matches:","code":"tibble::tibble(dopingdata::s2_substances) stringr::str_view_all(string = classified_single_aaf_substance$substance_reason,    pattern = s2_regex, match = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"s3-beta-2-agonists","dir":"Articles","previous_headings":"Classifying substances","what":"S3 BETA-2 AGONISTS","title":"AAF substances sanctions","text":"S3 substances : Check matches:","code":"tibble::tibble(dopingdata::s3_substances) stringr::str_view_all(string = classified_single_aaf_substance$substance_reason,    pattern = s3_regex, match = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"s4-hormone-and-metabolic-modulators","dir":"Articles","previous_headings":"Classifying substances","what":"S4 HORMONE AND METABOLIC MODULATORS","title":"AAF substances sanctions","text":"S4 substances : Check matches:","code":"tibble::tibble(dopingdata::s4_substances) stringr::str_view_all(string = classified_single_aaf_substance$substance_reason,    pattern = s4_regex, match = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"s5-diureticsmasking-agents","dir":"Articles","previous_headings":"Classifying substances","what":"S5 DIURETICS/MASKING AGENTS","title":"AAF substances sanctions","text":"S5 substances : Check matches:","code":"tibble::tibble(dopingdata::s5_substances) stringr::str_view_all(string = classified_single_aaf_substance$substance_reason,    pattern = s5_regex, match = TRUE)"},{"path":[]},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"m1-manipulation-of-blood","dir":"Articles","previous_headings":"PROHIBITED METHODS","what":"M1 MANIPULATION OF BLOOD","title":"AAF substances sanctions","text":"M1 substances : Check matches:","code":"tibble::tibble(dopingdata::m1_method) stringr::str_view_all(string = classified_single_aaf_substance$substance_reason,    pattern = m1_regex, match = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"m2-chemical-and-physical-manipulation","dir":"Articles","previous_headings":"PROHIBITED METHODS","what":"M2 CHEMICAL AND PHYSICAL MANIPULATION","title":"AAF substances sanctions","text":"M2 substances : Check matches:","code":"tibble::tibble(dopingdata::m2_method) stringr::str_view_all(string = classified_single_aaf_substance$substance_reason,    pattern = m2_regex, match = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"m3-gene-and-cell-doping","dir":"Articles","previous_headings":"PROHIBITED METHODS","what":"M3 GENE AND CELL DOPING","title":"AAF substances sanctions","text":"M3 substances : Check matches:","code":"tibble::tibble(dopingdata::m3_method) stringr::str_view_all(string = classified_single_aaf_substance$substance_reason,    pattern = m3_regex, match = TRUE)"},{"path":[]},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"s6-stimulants","dir":"Articles","previous_headings":"SUBSTANCES & METHODS PROHIBITED IN-COMPETITION","what":"S6 STIMULANTS","title":"AAF substances sanctions","text":"S6 STIMULANTS, including optical isomers, e.g. d- l- relevant, prohibited. S6 substances : Check matches:","code":"tibble::tibble(dopingdata::s6_substances) stringr::str_view_all(string = classified_single_aaf_substance$substance_reason,    pattern = s6_regex, match = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"s7-narcotics","dir":"Articles","previous_headings":"SUBSTANCES & METHODS PROHIBITED IN-COMPETITION","what":"S7 NARCOTICS","title":"AAF substances sanctions","text":"S7 substances : Check matches:","code":"tibble::tibble(dopingdata::s7_substances) stringr::str_view_all(string = classified_single_aaf_substance$substance_reason,    pattern = s7_regex, match = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"s8-cannabinoids","dir":"Articles","previous_headings":"SUBSTANCES & METHODS PROHIBITED IN-COMPETITION","what":"S8 CANNABINOIDS","title":"AAF substances sanctions","text":"following cannabinoids prohibited: Natural cannabinoids, e.g. cannabis, hashish marijuana; Synthetic cannabinoids e.g. Δ9-tetrahydrocannabinol (THC) cannabimimetics. S8 substances : Check matches:","code":"tibble::tibble(dopingdata::s8_substances) stringr::str_view_all(string = classified_single_aaf_substance$substance_reason,    pattern = s8_regex, match = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"s9-glucocorticoids","dir":"Articles","previous_headings":"SUBSTANCES & METHODS PROHIBITED IN-COMPETITION","what":"S9 GLUCOCORTICOIDS","title":"AAF substances sanctions","text":"S9 substances : Check matches:","code":"tibble::tibble(dopingdata::s9_substances) stringr::str_view_all(string = classified_single_aaf_substance$substance_reason,    pattern = s9_regex, match = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"p1-beta-blockers-prohibited-in-competition-only","dir":"Articles","previous_headings":"SUBSTANCES & METHODS PROHIBITED IN-COMPETITION","what":"P1 BETA BLOCKERS (prohibited In-Competition only)","title":"AAF substances sanctions","text":"Beta-blockers prohibited -Competition , following sports, also prohibited --Competition indicated. archery (wa) automobile (fia) billiards (disciplines) (wcbs) darts (wdf) golf (igf) shooting (issf, ipc) skiing/snowboarding (fis) ski jumping, freestyle aerials/halfpipe snowboard halfpipe/big air underwater sports (cmas) constant-weight apnoea without fins, dynamic apnoea without fins, free immersion apnoea, jump blue apnoea, spearfishing, static apnoea, target shooting, variable weight apnoea S8 substances : Check matches:","code":"tibble::tibble(dopingdata::p1_substances) stringr::str_view_all(string = classified_single_aaf_substance$substance_reason,    pattern = p1_regex, match = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"unclassified-substances","dir":"Articles","previous_headings":"","what":"Unclassified substances","title":"AAF substances sanctions","text":"substances classified using standard WADA list stored unclass_single_aaf_substances. can use additional regular expressions classify_substance() function.","code":"unclass_single_aaf_substances <- classified_single_aaf_substance |>    filter(is.na(substance_group))  unclass_single_aaf_substances |>    count(substance_reason, sort = TRUE)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"elevated-te-3-whereabouts-failures","dir":"Articles","previous_headings":"Unclassified substances","what":"\"elevated t/e\" & 3 whereabouts failures","title":"AAF substances sanctions","text":"can use recode original values–start 3 whereabouts failures yair rodriguez non-analytical, can create tiny tibble bind back usada_substance_types (removing rodriguez, yair) Now can address elevated t/e (classify \"S1 ANABOLIC AGENTS\")","code":"classify_substance(   df = unclass_single_aaf_substances,    subs_col = substance_reason,    subs = \"elevated t/e\",    var = \"analytic\",   val = \"S1 ANABOLIC AGENTS\",   wb = FALSE) |>    classify_substance(   subs_col = substance_reason,    subs = \"3 whereabouts failures\",    var = \"non_analytic\",   val = \"3 whereabouts failures\",   wb = FALSE) |>    dplyr::filter(!is.na(analytic) | !is.na(non_analytic)) |>    dplyr::select(athlete, sanction_date, substance_reason, analytic, non_analytic) # get rodriguez, yair (3 whereabouts failures) miss_classified_sanction_type <- classified_single_aaf_substance |>    filter(athlete == \"rodriguez, yair\" &              sanction_date == lubridate::as_date(\"2020-12-03\")) |>    dplyr::mutate(sanction_type = if_else(sanction_type == \"analytical\",      true = \"non-analytical\", sanction_type)) |>    dplyr::select(-substance_group) usada_substance_types <- usada_substance_types |>    dplyr::filter(athlete != \"rodriguez, yair\" &              sanction_date != lubridate::as_date(\"2020-12-03\")) |>    dplyr::bind_rows(miss_classified_sanction_type) usada_substance_types |>    dplyr::filter(athlete == \"rodriguez, yair\") |>    dplyr::select(athlete, sanction_date, substance_reason, sanction_type) classified_single_aaf_substance <- classified_single_aaf_substance |>    dplyr::mutate(     substance_group = case_when(       stringr::str_detect(substance_reason, \"elevated t/e\") ~ \"S1 ANABOLIC AGENTS\"))   classified_single_aaf_substance |>    dplyr::filter(str_detect(athlete, \"kirk\")) |>    dplyr::select(athlete, sanction_date, substance_reason, sanction_type)"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"export-sanction-data","dir":"Articles","previous_headings":"","what":"Export sanction data","title":"AAF substances sanctions","text":"Export analytic sanctions:","code":"new_pth <- paste0(\"../inst/extdata/\", Sys.Date(), \"/\") fs::dir_create(new_pth) file_pth <- paste0(new_pth, dtstamp(side = \"r\"),                      \"usada_sanction_types.csv\") file_pth vroom::vroom_write(x = usada_sanction_types, file = file_pth, delim = \",\") fs::dir_tree(new_pth, regexp = \"usada_sanction\")"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"export-substance-data","dir":"Articles","previous_headings":"","what":"Export substance data","title":"AAF substances sanctions","text":"","code":"new_pth <- paste0(\"../inst/extdata/\", tdy_stmp, \"/\") file_pth <- paste0(new_pth, dtstamp(side = \"r\"), \"usada_substance_types.csv\") file_pth vroom::vroom_write(x = usada_substance_types, file = file_pth, delim = \",\") fs::dir_tree(new_pth, regexp = \"usada_substance_types\")"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"export-classified-single-substances","dir":"Articles","previous_headings":"","what":"Export classified (single) substances","title":"AAF substances sanctions","text":"Export classified single substances:","code":"new_pth <- paste0(\"../inst/extdata/\", tdy_stmp, \"/\") file_pth <- paste0(new_pth,                    dtstamp(side = \"r\"), \"classified_single_aaf_substance.csv\") file_pth vroom::vroom_write(x = classified_single_aaf_substance,    file = file_pth, delim = \",\") fs::dir_tree(new_pth, regexp = \"classified_single_aaf_substance\")"},{"path":[]},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-aaf-substances.html","id":"wada-list","dir":"Articles","previous_headings":"Appendix","what":"WADA list","title":"AAF substances sanctions","text":"copy original WADA substances available dopingdata::WADA","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-dates.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"Sanction dates","text":"vignette covers format wrangle sanction dates USADA sanctions table.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-dates.html","id":"data-versioning","dir":"Articles","previous_headings":"Motivation","what":"Data versioning","title":"Sanction dates","text":"package uses data table gets updated regularly. keep track versions, ’ve organized inst/extdata folder date (YYYY-MM-DD), helper function getting recent version: Now can use tdy_stmp whenever need use find data version! See :","code":"tdy_stmp <- get_recent_version(\"../inst/extdata/raw\") #> Loading required package: fs #> Loading required package: purrr #> ✔ Here is the recent date: tdy_stmp #>     tdy_stmp  #> \"2023-01-20\""},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-dates.html","id":"outline","dir":"Articles","previous_headings":"Motivation","what":"Outline","title":"Sanction dates","text":"vignette assumes following: Scrape website: copy USADA sanctions table scraped lives inst/extdata/raw/ folder See scrape_usada_sanctions() function scraping-usada.Rmd vignette information data column names formatted janitor::clean_names(), text converted lowercase","code":"#> ../inst/extdata/raw/2023-01-20 #> ├── 2023-01-20-usada_prohib_assoc_raw.csv #> ├── 2023-01-20-usada_prohib_assoc_raw.rds #> ├── 2023-01-20-usada_sanctions_raw.csv #> └── 2023-01-20-usada_sanctions_raw.rds"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-dates.html","id":"import-recent-data-file","dir":"Articles","previous_headings":"Motivation","what":"Import recent data file","title":"Sanction dates","text":"’ve written custom import function, get_recent_data_file(), helps locating/importing recent USADA data:","code":"get_recent_data_file(   folder = paste0(\"../inst/extdata/pro/\", tdy_stmp), type = \"csv\") ✔ import code pasted to clipboard! ✔ use: readr::read_csv('../inst/extdata/pro/2023-01-20/2023-01-20-usada_sanctions_pro.csv') usada_raw <- readr::read_csv(   '../inst/extdata/pro/2023-01-19/2023-01-19-usada_sanctions_pro.csv') #> Rows: 895 Columns: 5 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> chr (5): athlete, sport, substance_reason, sanction_terms, sanction_announced #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. dplyr::glimpse(usada_raw) #> Rows: 895 #> Columns: 5 #> $ athlete            <chr> \"montañez barroso, elias\", \"ruiz-gutierrez, noslen\"… #> $ sport              <chr> \"cycling\", \"cycling\", \"track and field\", \"cycling\",… #> $ substance_reason   <chr> \"non-analytical: refusal to submit to sample collec… #> $ sanction_terms     <chr> \"4-year suspension; loss of results\", \"4-year suspe… #> $ sanction_announced <chr> \"01/10/2023\", \"01/04/2023\", \"12/08/2022\", \"12/05/20…"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-dates.html","id":"sanction-dates","dir":"Articles","previous_headings":"Motivation > Import recent data file","what":"Sanction dates","title":"Sanction dates","text":"need format dates sanction_announced actual date, check see ’re format. ones failed? Store bad_dates. can see ’ve stuffed two dates sanction_announced column 29 athletes: use tidyr::separate_rows() split dates original updated Remove excess colons white-space stringr::str_remove_all() filter original dates (want updated date) convert dates date anytime::anydate() take care single outlier (formatted two-year date) remove sanction_announced column (use sanction_date instead) Now want format dates usada_raw using anytime::anydate(), filter missing sanction_dates didn’t parse, remove sanction_announced column, bind back good_dates table fixed sanction dates.","code":"dplyr::mutate(usada_raw,    sanction_announced = lubridate::mdy(sanction_announced)) |>    utils::head(25) #> Warning: 29 failed to parse. #> # A tibble: 25 × 5 #>    athlete                       sport                subst…¹ sanct…² sanction…³ #>    <chr>                         <chr>                <chr>   <chr>   <date>     #>  1 \"montañez barroso, elias\"     cycling              non-an… 4-year… 2023-01-10 #>  2 \"ruiz-gutierrez, noslen\"      cycling              dexame… 4-year… 2023-01-04 #>  3 \"roberts, gil\"                track and field      andari… 16-mon… 2022-12-08 #>  4 \"andrew, sidney\"              cycling              5-meth… 12-mon… 2022-12-05 #>  5 \"rodriguez ocasio, christian\" weightlifting        heptam… 12-mon… 2022-11-30 #>  6 \"scherf, lindsey\"             track and field      androg… 4-year… 2022-11-29 #>  7 \"mead, hassan\"                track and field      ostari… 3-year… 2022-11-29 #>  8 \"evans, aja\"                  bobsled              non-an… 2-year… 2022-11-18 #>  9 \"scantling, garrett\"          track and field      non-an… 3-year… 2022-11-18 #> 10 \"provisor, ben\"               wrestling            amphet… 16-mon… 2022-11-15 #> 11 \"skoog, arika\"                boxing               furose… 1-year… 2022-10-26 #> 12 \"navarrete, rene\"             weightlifting        cannab… 3-mont… 2022-10-14 #> 13 \"green, bobby\"                mixed martial arts   dehydr… 6-mont… 2022-10-07 #> 14 \"guimarães, catarina\"         para track and field non-an… public… 2022-10-05 #> 15 \"bringas, joshua\"             weightlifting        heptam… 3-year… 2022-09-26 #> 16 \"zaleski dos santos, elizeu\"  mixed martial arts   ostari… 1-year… 2022-09-22 #> 17 \"ray, olivia\"                 cycling              human … 30-mon… 2022-09-22 #> 18 \"browne, richard\"             para track and field cannab… 3-mont… 2022-09-07 #> 19 \"hearn, timothy\"              weightlifting        19-nor… 3-year… 2022-09-06 #> 20 \"trujillo, nelson\"            cycling              non-an… 12-yea… 2022-09-02 #> 21 \"jordan, clint\"               weightlifting        anabol… 4-year… 2022-09-01 #> 22 \"coleman, ellis\"              wrestling            dehydr… 24-mon… 2022-08-31 #> 23 \"walker, gregory\"             para track and field cannab… 3-mont… 2022-08-16 #> 24 \"hattingh, riekert\"           rugby                tamoxi… 6-mont… 2022-08-11 #> 25 \"nash, jackson \\\"huntley\\\"\"   cycling              non-an… lifeti… 2022-08-10 #> # … with abbreviated variable names ¹​substance_reason, ²​sanction_terms, #> #   ³​sanction_announced bad_dates <- mutate(usada_raw,    sanction_date = lubridate::mdy(sanction_announced)) |>    dplyr::filter(is.na(sanction_date) & !is.na(sanction_announced))  #> Warning: 29 failed to parse. bad_dates |>    dplyr::select(sanction_announced) |>    head(10) #> # A tibble: 10 × 1 #>    sanction_announced                        #>    <chr>                                     #>  1 original: 05/07/2019; updated: 02/04/2022 #>  2 original: 09/03/21; updated: 01/25/22     #>  3 original:  11/04/2019;updated: 05/17/2021 #>  4 original 12/20/2018; updated 11/04/2020   #>  5 original: 10/19/2020updated: 01/05/2021   #>  6 original: 09/05/2019; updated: 08/26/2020 #>  7 original: 07/22/2020, updated: 11/03/2022 #>  8 original 09/11/2018; updated 01/16/2020   #>  9 original: 06/17/2019; updated: 12/16/2019 #> 10 original: 10/31/2017; updated: 12/16/2019 good_dates <- tidyr::separate_rows(data = bad_dates,   sanction_announced, sep = \"updated\") |>   dplyr::mutate(sanction_date = stringr::str_remove_all(sanction_announced, \": \")) |>   dplyr::filter(!stringr::str_detect(sanction_date, \"^original\")) |>   dplyr::mutate(sanction_date = anytime::anydate(sanction_date)) |>   dplyr::mutate(     sanction_date = dplyr::case_when(       athlete == \"ngetich, eliud\" ~ lubridate::as_date(\"2022-01-25\"),       TRUE ~ sanction_date     )   ) |>   dplyr::select(-sanction_announced) good_dates |> glimpse() #> Rows: 29 #> Columns: 5 #> $ athlete          <chr> \"prempeh, ernest\", \"ngetich, eliud\", \"gehm, zach\", \"h… #> $ sport            <chr> \"weightlifting\", \"track and field\", \"track and field\"… #> $ substance_reason <chr> \"dhcmt, androgenic anabolic steroids; non-analytical:… #> $ sanction_terms   <chr> \"4-year suspension; loss of results; sanction tolled … #> $ sanction_date    <date> 2022-02-04, 2022-01-25, 2021-05-17, 2020-11-04, 2021… usada_dates <- dplyr::mutate(usada_raw,      sanction_date = anytime::anydate(sanction_announced)) |>    dplyr::filter(!is.na(sanction_date)) |>    dplyr::select(-sanction_announced) |>    dplyr::bind_rows(good_dates)  dplyr::glimpse(usada_dates) #> Rows: 658 #> Columns: 5 #> $ athlete          <chr> \"montañez barroso, elias\", \"ruiz-gutierrez, noslen\", … #> $ sport            <chr> \"cycling\", \"cycling\", \"track and field\", \"cycling\", \"… #> $ substance_reason <chr> \"non-analytical: refusal to submit to sample collecti… #> $ sanction_terms   <chr> \"4-year suspension; loss of results\", \"4-year suspens… #> $ sanction_date    <date> 2023-01-10, 2023-01-04, 2022-12-08, 2022-12-05, 2022…"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-dates.html","id":"export","dir":"Articles","previous_headings":"Motivation","what":"Export","title":"Sanction dates","text":"Create paths today’s data: Export usada_dates .csv .rds Verify","code":"new_pth <- paste0(\"../inst/extdata/der/\") fs::dir_create(new_pth) csv_pth <- paste0(new_pth, \"sanction_dates.csv\") csv_pth #> [1] \"../inst/extdata/der/sanction_dates.csv\" vroom::vroom_write(x = usada_dates, file = csv_pth, delim = \",\") fs::dir_tree(new_pth, regexp = \"dates\") #> ../inst/extdata/der/ #> └── sanction_dates.csv"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-sports.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"Sanction sports","text":"vignette covers sports listed USADA sanctions table.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-sports.html","id":"data-versioning","dir":"Articles","previous_headings":"","what":"Data versioning","title":"Sanction sports","text":"package uses data table gets updated regularly. keep track versions, ’ve organized inst/extdata folder date (YYYY-MM-DD), helper function getting recent version: Now can use tdy_stmp whenever need use find data version! See :","code":"tdy_stmp <- get_recent_version(\"../inst/extdata/raw\") #> Loading required package: fs #> Loading required package: purrr #> ✔ Here is the recent date: tdy_stmp #>     tdy_stmp  #> \"2023-01-20\""},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-sports.html","id":"outline","dir":"Articles","previous_headings":"","what":"Outline","title":"Sanction sports","text":"vignette assumes following: Scrape website: copy USADA sanctions table scraped lives inst/extdata/raw/ inst/extdata/pro/ folders See scrape_usada_sanctions() function scraping-usada-sanctions.Rmd vignette information data column names formatted janitor::clean_names(), text converted lowercase Fix dates: dates table formatted wrangled See vignettes/sanction-dates.Rmd vignette information","code":"#> ../inst/extdata/raw/2023-01-20 #> ├── 2023-01-20-usada_sanctions_raw.csv #> └── 2023-01-20-usada_sanctions_raw.rds ``` #>  [01;34m../inst/extdata/pro/2023-01-20 [0m #> ├── 2023-01-20-usada_sanctions_pro.csv #> └── 2023-01-20-usada_sanctions_pro.rds ``` #> ../inst/extdata/der/ #> └── sanction_dates.csv"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-sports.html","id":"data","dir":"Articles","previous_headings":"Outline","what":"Data","title":"Sanction sports","text":"’m going locate recently wrangled data file inst/extdata/pro/ folder: path clipboard exported data vignettes/sanction-dates.Rmd (, please head vignette fix dates moving forward).","code":"get_recent_data_file(   folder = paste0(\"../inst/extdata/der/\", tdy_stmp),    type = \"csv\") ✔ import code pasted to clipboard! ✔ use: readr::read_csv('../inst/extdata/der/sanction_dates.csv') sanctions <- readr::read_csv(   file = '../inst/extdata/der/sanction_dates.csv') #> Rows: 658 Columns: 5 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> chr  (4): athlete, sport, substance_reason, sanction_terms #> date (1): sanction_date #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. dplyr::glimpse(sanctions) #> Rows: 658 #> Columns: 5 #> $ athlete          <chr> \"montañez barroso, elias\", \"ruiz-gutierrez, noslen\", … #> $ sport            <chr> \"cycling\", \"cycling\", \"track and field\", \"cycling\", \"… #> $ substance_reason <chr> \"non-analytical: refusal to submit to sample collecti… #> $ sanction_terms   <chr> \"4-year suspension; loss of results\", \"4-year suspens… #> $ sanction_date    <date> 2023-01-10, 2023-01-04, 2022-12-08, 2022-12-05, 2022…"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-sports.html","id":"sport-counts-raw","dir":"Articles","previous_headings":"","what":"sport counts (raw)","title":"Sanction sports","text":"","code":"sanctions |>    dplyr::count(sport, sort = TRUE) #> # A tibble: 69 × 2 #>    sport                                           n #>    <chr>                                       <int> #>  1 cycling                                       132 #>  2 mixed martial arts                            128 #>  3 weightlifting                                 116 #>  4 track and field                                99 #>  5 wrestling                                      15 #>  6 triathlon                                      14 #>  7 paralympic track and field                     11 #>  8 swimming                                       10 #>  9 boxing                                          8 #> 10 brazilian jiu-jitsu                             7 #> 11 cycling - athlete support personnel             6 #> 12 rowing                                          6 #> 13 taekwondo                                       6 #> 14 track and field - athlete support personnel     6 #> 15 bobsled and skeleton                            5 #> 16 ice hockey                                      5 #> 17 judo                                            5 #> 18 paralympic judo                                 4 #> 19 archery                                         3 #> 20 cycling, triathlon                              3 #> 21 karate                                          3 #> 22 para track and field                            3 #> 23 paralympic cycling                              3 #> 24 rugby                                           3 #> 25 speedskating                                    3 #> # … with 44 more rows"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-sports.html","id":"athlete-support-personnel","dir":"Articles","previous_headings":"sport counts (raw)","what":"athlete support personnel","title":"Sanction sports","text":"’ll create identifier athlete support personnel, support_personnel.","code":"dplyr::mutate(sanctions,    # support_personnel   support_personnel =      dplyr::if_else(condition = stringr::str_detect(sport, \"support personnel\"),        true = TRUE, false = FALSE, missing = NA)) |>    dplyr::count(sport, support_personnel) |>    tidyr::pivot_wider(names_from = support_personnel, values_from = n) #> # A tibble: 69 × 3 #>    sport                                           `FALSE` `TRUE` #>    <chr>                                             <int>  <int> #>  1 archery                                               3     NA #>  2 baseball                                              1     NA #>  3 bobsled                                               1     NA #>  4 bobsled and skeleton                                  5     NA #>  5 bobsled and skeleton, track and field                 1     NA #>  6 boccia                                                2     NA #>  7 bowling                                               1     NA #>  8 boxing                                                8     NA #>  9 brazilian jiu-jitsu                                   7     NA #> 10 brazilian jiu-jitsu - athlete support personnel      NA      1 #> 11 brazillian jiu-jitsu                                  1     NA #> 12 canoe                                                 1     NA #> 13 cycling                                             132     NA #> 14 cycling - athlete support personnel                  NA      6 #> 15 cycling, triathlon                                    3     NA #> 16 cycling, weightlifting                                1     NA #> 17 diving                                                2     NA #> 18 equestrian                                            1     NA #> 19 field hockey                                          1     NA #> 20 gymnastics                                            1     NA #> 21 ice hockey                                            5     NA #> 22 judo                                                  5     NA #> 23 karate                                                3     NA #> 24 luge                                                  1     NA #> 25 mixed martial arts                                  128     NA #> # … with 44 more rows"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-sports.html","id":"track-and-field","dir":"Articles","previous_headings":"sport counts (raw)","what":"track and field","title":"Sanction sports","text":"’m going convert track field track & field (help determine athletes/support personnel involved multiple sports).","code":"dplyr::mutate(sanctions,   # support_personnel   support_personnel =      dplyr::if_else(condition = stringr::str_detect(sport, \"support personnel\"),        true = TRUE, false = FALSE, missing = NA),   # track & field   sport = stringr::str_replace_all(sport, 'track and field', 'track & field')) |>    dplyr::count(sport, sort = TRUE) #> # A tibble: 68 × 2 #>    sport                                         n #>    <chr>                                     <int> #>  1 cycling                                     132 #>  2 mixed martial arts                          128 #>  3 weightlifting                               116 #>  4 track & field                               101 #>  5 wrestling                                    15 #>  6 triathlon                                    14 #>  7 paralympic track & field                     11 #>  8 swimming                                     10 #>  9 boxing                                        8 #> 10 brazilian jiu-jitsu                           7 #> 11 cycling - athlete support personnel           6 #> 12 rowing                                        6 #> 13 taekwondo                                     6 #> 14 track & field - athlete support personnel     6 #> 15 bobsled and skeleton                          5 #> 16 ice hockey                                    5 #> 17 judo                                          5 #> 18 paralympic judo                               4 #> 19 archery                                       3 #> 20 cycling, triathlon                            3 #> 21 karate                                        3 #> 22 para track & field                            3 #> 23 paralympic cycling                            3 #> 24 rugby                                         3 #> 25 speedskating                                  3 #> # … with 43 more rows"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-sports.html","id":"brazilian-jiu-jitsu","dir":"Articles","previous_headings":"sport counts (raw)","what":"brazilian jiu-jitsu","title":"Sanction sports","text":"incorrect spelling brazilian jiu-jitsu (brazillian jiu-jitsu), correct :","code":"dplyr::mutate(sanctions,    # # support_personnel   support_personnel =      dplyr::if_else(condition = stringr::str_detect(sport, \"support personnel\"),        true = TRUE, false = FALSE, missing = NA),   # track & field   sport = stringr::str_replace_all(sport, 'track and field', 'track & field'),   # brazilian jiu-jitsu   sport = dplyr::case_when(     sport == 'brazillian jiu-jitsu' ~ 'brazilian jiu-jitsu',     TRUE ~ sport)) |>    dplyr::count(sport, sort = TRUE) #> # A tibble: 67 × 2 #>    sport                                         n #>    <chr>                                     <int> #>  1 cycling                                     132 #>  2 mixed martial arts                          128 #>  3 weightlifting                               116 #>  4 track & field                               101 #>  5 wrestling                                    15 #>  6 triathlon                                    14 #>  7 paralympic track & field                     11 #>  8 swimming                                     10 #>  9 boxing                                        8 #> 10 brazilian jiu-jitsu                           8 #> 11 cycling - athlete support personnel           6 #> 12 rowing                                        6 #> 13 taekwondo                                     6 #> 14 track & field - athlete support personnel     6 #> 15 bobsled and skeleton                          5 #> 16 ice hockey                                    5 #> 17 judo                                          5 #> 18 paralympic judo                               4 #> 19 archery                                       3 #> 20 cycling, triathlon                            3 #> 21 karate                                        3 #> 22 para track & field                            3 #> 23 paralympic cycling                            3 #> 24 rugby                                         3 #> 25 speedskating                                  3 #> # … with 42 more rows"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-sports.html","id":"paralympic","dir":"Articles","previous_headings":"sport counts (raw)","what":"paralympic","title":"Sanction sports","text":"’ll also create identifier paralympic sports, paralympic.","code":"dplyr::mutate(sanctions,    # support_personnel   support_personnel =      dplyr::if_else(condition = stringr::str_detect(sport, \"support personnel\"),        true = TRUE, false = FALSE, missing = NA),   # track & field   sport = stringr::str_replace_all(sport, 'track and field', 'track & field'),   # brazilian jiu-jitsu   sport = dplyr::case_when(     sport == 'brazillian jiu-jitsu' ~ 'brazilian jiu-jitsu',     TRUE ~ sport),   # paralympic   paralympic =      dplyr::if_else(condition = stringr::str_detect(sport, \"paralympic|para\"),        true = TRUE, false = FALSE, missing = NA)) |>    dplyr::count(paralympic, sport) |>    tidyr::pivot_wider(names_from = paralympic, values_from = n) #> # A tibble: 67 × 3 #>    sport                                           `FALSE` `TRUE` #>    <chr>                                             <int>  <int> #>  1 archery                                               3     NA #>  2 baseball                                              1     NA #>  3 bobsled                                               1     NA #>  4 bobsled and skeleton                                  5     NA #>  5 bobsled and skeleton, track & field                   1     NA #>  6 boccia                                                2     NA #>  7 bowling                                               1     NA #>  8 boxing                                                8     NA #>  9 brazilian jiu-jitsu                                   8     NA #> 10 brazilian jiu-jitsu - athlete support personnel       1     NA #> 11 canoe                                                 1     NA #> 12 cycling                                             132     NA #> 13 cycling - athlete support personnel                   6     NA #> 14 cycling, triathlon                                    3     NA #> 15 cycling, weightlifting                                1     NA #> 16 diving                                                2     NA #> 17 equestrian                                            1     NA #> 18 field hockey                                          1     NA #> 19 gymnastics                                            1     NA #> 20 ice hockey                                            5     NA #> 21 judo                                                  5     NA #> 22 karate                                                3     NA #> 23 luge                                                  1     NA #> 24 mixed martial arts                                  128     NA #> 25 pentathlon                                            1     NA #> # … with 42 more rows"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-sports.html","id":"multiple_sports","dir":"Articles","previous_headings":"sport counts (raw)","what":"multiple_sports","title":"Sanction sports","text":"Now can identify multiple sports using , regular expression.","code":"dplyr::mutate(sanctions,    # support_personnel   support_personnel =      if_else(condition = stringr::str_detect(sport, \"support personnel\"),        true = TRUE, false = FALSE, missing = NA),   # track & field   sport = stringr::str_replace_all(sport, 'track and field', 'track & field'),   # brazilian jiu-jitsu   sport = case_when(     sport == 'brazillian jiu-jitsu' ~ 'brazilian jiu-jitsu',     TRUE ~ sport),   # multiple_sports   multiple_sports =      if_else(condition = stringr::str_detect(sport, \"and |, \"),        true = TRUE, false = FALSE, missing = NA),   # paralympic   paralympic =      if_else(condition = stringr::str_detect(sport, \"paralympic|para\"),        true = TRUE, false = FALSE, missing = NA)) |>    dplyr::count(multiple_sports, sport) |>    tidyr::pivot_wider(names_from = multiple_sports, values_from = n) #> # A tibble: 67 × 3 #>    sport                                           `FALSE` `TRUE` #>    <chr>                                             <int>  <int> #>  1 archery                                               3     NA #>  2 baseball                                              1     NA #>  3 bobsled                                               1     NA #>  4 boccia                                                2     NA #>  5 bowling                                               1     NA #>  6 boxing                                                8     NA #>  7 brazilian jiu-jitsu                                   8     NA #>  8 brazilian jiu-jitsu - athlete support personnel       1     NA #>  9 canoe                                                 1     NA #> 10 cycling                                             132     NA #> 11 cycling - athlete support personnel                   6     NA #> 12 diving                                                2     NA #> 13 equestrian                                            1     NA #> 14 field hockey                                          1     NA #> 15 gymnastics                                            1     NA #> 16 ice hockey                                            5     NA #> 17 judo                                                  5     NA #> 18 karate                                                3     NA #> 19 luge                                                  1     NA #> 20 mixed martial arts                                  128     NA #> 21 para shooting                                         1     NA #> 22 para track & field                                    3     NA #> 23 paralympic archery                                    2     NA #> 24 paralympic basketball                                 2     NA #> 25 paralympic boccia                                     1     NA #> # … with 42 more rows"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-sports.html","id":"sanctions_sports","dir":"Articles","previous_headings":"","what":"sanctions_sports","title":"Sanction sports","text":"’ll store new variables sanctions_sports","code":"sanctions_sports <- dplyr::mutate(sanctions,    # support_personnel   support_personnel =      dplyr::if_else(condition = stringr::str_detect(sport, \"support personnel\"),        true = TRUE, false = FALSE, missing = NA),   # track & field   sport = stringr::str_replace_all(sport, 'track and field', 'track & field'),   # brazilian jiu-jitsu   sport = case_when(     sport == 'brazillian jiu-jitsu' ~ 'brazilian jiu-jitsu',     TRUE ~ sport),   # multiple_sports   multiple_sports =      dplyr::if_else(condition = stringr::str_detect(sport, \"and |, \"),        true = TRUE, false = FALSE, missing = NA),   # paralympic   paralympic =      dplyr::if_else(condition = stringr::str_detect(sport, \"paralympic|para\"),        true = TRUE, false = FALSE, missing = NA))  dplyr::glimpse(sanctions_sports) #> Rows: 658 #> Columns: 8 #> $ athlete           <chr> \"montañez barroso, elias\", \"ruiz-gutierrez, noslen\",… #> $ sport             <chr> \"cycling\", \"cycling\", \"track & field\", \"cycling\", \"w… #> $ substance_reason  <chr> \"non-analytical: refusal to submit to sample collect… #> $ sanction_terms    <chr> \"4-year suspension; loss of results\", \"4-year suspen… #> $ sanction_date     <date> 2023-01-10, 2023-01-04, 2022-12-08, 2022-12-05, 202… #> $ support_personnel <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… #> $ multiple_sports   <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… #> $ paralympic        <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-sports.html","id":"multiple-sports","dir":"Articles","previous_headings":"sanctions_sports","what":"Multiple sports","title":"Sanction sports","text":"athletes listed multiple sports, means ’ll occupy multiple rows ‘tidy’ version dataset. can check using count() verify one athlete sport:","code":"sanctions_sports |>    dplyr::filter(multiple_sports == TRUE) |>    tidyr::separate_rows(sport, sep = \"and|, \") |>    dplyr::count(athlete, sport) #> # A tibble: 31 × 3 #>    athlete                  sport                          n #>    <chr>                    <chr>                      <int> #>  1 allison, kyler           \" skeleton\"                    1 #>  2 allison, kyler           \"bobsled \"                     1 #>  3 bailey, ryan             \" skeleton\"                    1 #>  4 bailey, ryan             \"bobsled \"                     1 #>  5 bailey, ryan             \"track & field\"                1 #>  6 bascio, monica           \"paralympic cycling\"           1 #>  7 bascio, monica           \"paralympic nordic skiing\"     1 #>  8 blandford, jenna         \"cycling\"                      1 #>  9 blandford, jenna         \"triathlon\"                    1 #> 10 cruse, j.c.              \" skeleton\"                    1 #> 11 cruse, j.c.              \"bobsled \"                     1 #> 12 denney phillips, jessica \"cycling\"                      1 #> 13 denney phillips, jessica \"weightlifting\"                1 #> 14 dodson, amy              \"paralympic track & field\"     1 #> 15 dodson, amy              \"paralympic triathlon\"         1 #> 16 flanagan, tyler          \" snowboarding\"                1 #> 17 flanagan, tyler          \"skiing \"                      1 #> 18 green, roderick          \"paralympic track & field\"     1 #> 19 green, roderick          \"paralympic volleyball\"        1 #> 20 hamilton, tyler          \"cycling\"                      1 #> 21 hamilton, tyler          \"triathlon\"                    1 #> 22 ives, kevin              \" skeleton\"                    1 #> 23 ives, kevin              \"bobsled \"                     1 #> 24 jones, randy             \" skeleton\"                    1 #> 25 jones, randy             \"bobsled \"                     1 #> # … with 6 more rows"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-sports.html","id":"tidy_multp_sports","dir":"Articles","previous_headings":"sanctions_sports","what":"tidy_multp_sports","title":"Sanction sports","text":"’ll remove white-space left tidyr::separate_rows() stringr::str_trim() create tidy_multp_sports.","code":"tidy_multp_sports <- sanctions_sports |>    dplyr::filter(multiple_sports == TRUE) |>    tidyr::separate_rows(sport, sep = \"and|, \") |>    dplyr::mutate(sport = stringr::str_trim(sport, side = \"both\")) glimpse(tidy_multp_sports) #> Rows: 31 #> Columns: 8 #> $ athlete           <chr> \"allison, kyler\", \"allison, kyler\", \"blandford, jenn… #> $ sport             <chr> \"bobsled\", \"skeleton\", \"cycling\", \"triathlon\", \"bobs… #> $ substance_reason  <chr> \"non-analytical: refusal to submit to sample collect… #> $ sanction_terms    <chr> \"4-year suspension; loss of results; sanction tolled… #> $ sanction_date     <date> 2019-10-09, 2019-10-09, 2017-11-28, 2017-11-28, 201… #> $ support_personnel <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… #> $ multiple_sports   <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE… #> $ paralympic        <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-sports.html","id":"single_usada_sports","dir":"Articles","previous_headings":"sanctions_sports","what":"single_usada_sports","title":"Sanction sports","text":"need remove single occurrences athletes sanctions_sports replace tidy athlete names. Verify aren’t duplicates single_usada_sports (zero rows )","code":"multp_sports_athletes <- unique(tidy_multp_sports['athlete']) single_usada_sports <- dplyr::filter(sanctions_sports,                                          athlete %nin% multp_sports_athletes) single_usada_sports |>    dplyr::count(athlete, sanction_date, sport) |>    dplyr::filter(n > 1) #> # A tibble: 0 × 4 #> # … with 4 variables: athlete <chr>, sanction_date <date>, sport <chr>, n <int>"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/sanction-sports.html","id":"tidy_sports","dir":"Articles","previous_headings":"","what":"tidy_sports","title":"Sanction sports","text":"Now combine tidy_sports verify aren’t duplicates (). Ready export! Export tidy_sports Verify CHECK: Can can see dates sports data data folder?","code":"tidy_sports <- dplyr::bind_rows(single_usada_sports, tidy_multp_sports) tidy_sports |>    dplyr::count(athlete, sanction_date, sport) |>    dplyr::filter(n > 1) #> # A tibble: 0 × 4 #> # … with 4 variables: athlete <chr>, sanction_date <date>, sport <chr>, n <int> dplyr::glimpse(tidy_sports) #> Rows: 689 #> Columns: 8 #> $ athlete           <chr> \"montañez barroso, elias\", \"ruiz-gutierrez, noslen\",… #> $ sport             <chr> \"cycling\", \"cycling\", \"track & field\", \"cycling\", \"w… #> $ substance_reason  <chr> \"non-analytical: refusal to submit to sample collect… #> $ sanction_terms    <chr> \"4-year suspension; loss of results\", \"4-year suspen… #> $ sanction_date     <date> 2023-01-10, 2023-01-04, 2022-12-08, 2022-12-05, 202… #> $ support_personnel <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… #> $ multiple_sports   <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… #> $ paralympic        <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… new_pth <- \"../inst/extdata/der/\" fs::dir_create(new_pth) csv_pth <- paste0(new_pth, \"tidy_sports.csv\") csv_pth #> [1] \"../inst/extdata/der/tidy_sports.csv\" vroom::vroom_write(x = tidy_sports, file = csv_pth, delim = \",\") fs::dir_tree(new_pth, regexp = \"tidy_sports|dates\") #> ../inst/extdata/der/ #> ├── sanction_dates.csv #> └── tidy_sports.csv"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-proh-assoc.html","id":"usada-prohibited-association-data","dir":"Articles","previous_headings":"","what":"USADA prohibited association data","title":"Scraping USADA prohibited associations","text":"data ’ll downloading comes USADA prohibited association table.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-proh-assoc.html","id":"use-your-manners","dir":"Articles","previous_headings":"","what":"Use your manners","title":"Scraping USADA prohibited associations","text":"package built top efforts fine people collected, organized, shared data, ’re going use polite package harvesting HTML tables. install package, run code : polite many options ethically scraping data (check package website information), ’ve chosen follow handy polite template:","code":"remotes::install_github(\"dmi3kno/polite\") library(polite) polite::use_manners()"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-proh-assoc.html","id":"check-robots-txt","dir":"Articles","previous_headings":"Use your manners","what":"Check robots.txt","title":"Scraping USADA prohibited associations","text":"’ll check robots.txt file scraping website: paths TRUE. ’ll also check domain robotstxt::get_robotstxt(): can see Allow: / configuration gives us access download data.","code":"# retrieval rtxt <- robotstxt::robotstxt(domain = \"https://www.usada.org/\")  # printing rtxt$check(   paths = c(\"news/\",              \"news/prohibited-association/\"),   bot   = \"*\" ) #> [1] TRUE TRUE rt <- robotstxt::get_robotstxt(   domain = \"https://www.usada.org/news/prohibited-association/\") # printing cat(rt[1]) #> # robots.txt overwrite by: on_suspect_content #>  #> User-agent: * #> Allow: /"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-proh-assoc.html","id":"scraping-with-polite-and-rvest","dir":"Articles","previous_headings":"Use your manners","what":"Scraping with polite and rvest","title":"Scraping USADA prohibited associations","text":"steps used scrape prohibited associations table:","code":"usada_url = \"https://www.usada.org/news/prohibited-association/\" usada_nodes <- polite::bow(usada_url) |>    polite::scrape() |>    rvest::html_nodes(\"table\")  usada_prohib_assoc_raw <- rvest::html_table(usada_nodes[[1]]) dplyr::glimpse(usada_prohib_assoc_raw) #> Rows: 18 #> Columns: 2 #> $ NAME                            <chr> \"Chavez, Bernabe\", \"Prempeh, Ernest\", … #> $ `SUSPENSION ENDS\\n(mm/dd/yyyy)` <chr> \"09/01/2025\", \"Indefinite*\", \"07/26/20…"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-proh-assoc.html","id":"process-text","dir":"Articles","previous_headings":"","what":"Process text","title":"Scraping USADA prohibited associations","text":"process_text() function lowercase text dataset. also applies janitor::clean_names() column names:","code":"usada_prohib_assoc_pro <- process_text(usada_prohib_assoc_raw) dplyr::glimpse(usada_prohib_assoc_pro) #> Rows: 18 #> Columns: 2 #> $ name                       <chr> \"chavez, bernabe\", \"prempeh, ernest\", \"dani… #> $ suspension_ends_mm_dd_yyyy <chr> \"09/01/2025\", \"indefinite*\", \"07/26/2025\", …"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-proh-assoc.html","id":"column-names","dir":"Articles","previous_headings":"Process text","what":"Column names","title":"Scraping USADA prohibited associations","text":"can change name suspension_ends_mm_dd_yyyy suspend_end:","code":"dplyr::rename(usada_prohib_assoc_pro,    suspend_end = suspension_ends_mm_dd_yyyy) #> # A tibble: 18 × 2 #>    name                 suspend_end #>    <chr>                <chr>       #>  1 chavez, bernabe      09/01/2025  #>  2 prempeh, ernest      indefinite* #>  3 daniels, jamaal      07/26/2025  #>  4 pearson, keir        lifetime    #>  5 glasgow, scott       08/09/2023  #>  6 brown, jeffrey       09/29/2023  #>  7 salazar, alberto     09/29/2023  #>  8 bell, kenta          lifetime    #>  9 gingras, michael     01/15/2029  #> 10 drummond, jon        12/16/2022  #> 11 bruyneel, johan      lifetime    #> 12 marti, jose          06/11/2027  #> 13 celaya lazama, pedro lifetime    #> 14 ferrari, dr. michele lifetime    #> 15 leinders, dr. geert  lifetime    #> 16 korchemny, remi      lifetime    #> 17 stewart, raymond     lifetime    #> 18 graham, trevor       lifetime"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-proh-assoc.html","id":"suspend_type","dir":"Articles","previous_headings":"Process text","what":"suspend_type","title":"Scraping USADA prohibited associations","text":"Create indicator variable (suspend_type) three categories suspensions: temporary, lifetime indefinite*","code":"dplyr::rename(usada_prohib_assoc_pro,    suspend_end = suspension_ends_mm_dd_yyyy) |>    dplyr::mutate(     suspend_type = dplyr::case_when(       stringr::str_detect(suspend_end, \"lifetime\") ~ \"lifetime\",       stringr::str_detect(suspend_end, \"indefinite*\") ~ \"indefinite*\",       TRUE ~ \"temporary\")) #> # A tibble: 18 × 3 #>    name                 suspend_end suspend_type #>    <chr>                <chr>       <chr>        #>  1 chavez, bernabe      09/01/2025  temporary    #>  2 prempeh, ernest      indefinite* indefinite*  #>  3 daniels, jamaal      07/26/2025  temporary    #>  4 pearson, keir        lifetime    lifetime     #>  5 glasgow, scott       08/09/2023  temporary    #>  6 brown, jeffrey       09/29/2023  temporary    #>  7 salazar, alberto     09/29/2023  temporary    #>  8 bell, kenta          lifetime    lifetime     #>  9 gingras, michael     01/15/2029  temporary    #> 10 drummond, jon        12/16/2022  temporary    #> 11 bruyneel, johan      lifetime    lifetime     #> 12 marti, jose          06/11/2027  temporary    #> 13 celaya lazama, pedro lifetime    lifetime     #> 14 ferrari, dr. michele lifetime    lifetime     #> 15 leinders, dr. geert  lifetime    lifetime     #> 16 korchemny, remi      lifetime    lifetime     #> 17 stewart, raymond     lifetime    lifetime     #> 18 graham, trevor       lifetime    lifetime"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-proh-assoc.html","id":"suspend_end","dir":"Articles","previous_headings":"Process text","what":"suspend_end","title":"Scraping USADA prohibited associations","text":"suspend_end contains dates represent date suspension ends.","code":"dplyr::rename(usada_prohib_assoc_pro,    suspend_end = suspension_ends_mm_dd_yyyy) |>    dplyr::mutate(     suspend_type = dplyr::case_when(       stringr::str_detect(suspend_end, \"lifetime\") ~ \"lifetime\",       stringr::str_detect(suspend_end, \"indefinite*\") ~ \"indefinite*\",       TRUE ~ \"temporary\"),     suspend_end = dplyr::case_when(       stringr::str_detect(suspend_end, \"lifetime|indefinite*\") ~ NA_character_,       TRUE ~ suspend_end),     suspend_end = lubridate::mdy(suspend_end)) #> # A tibble: 18 × 3 #>    name                 suspend_end suspend_type #>    <chr>                <date>      <chr>        #>  1 chavez, bernabe      2025-09-01  temporary    #>  2 prempeh, ernest      NA          indefinite*  #>  3 daniels, jamaal      2025-07-26  temporary    #>  4 pearson, keir        NA          lifetime     #>  5 glasgow, scott       2023-08-09  temporary    #>  6 brown, jeffrey       2023-09-29  temporary    #>  7 salazar, alberto     2023-09-29  temporary    #>  8 bell, kenta          NA          lifetime     #>  9 gingras, michael     2029-01-15  temporary    #> 10 drummond, jon        2022-12-16  temporary    #> 11 bruyneel, johan      NA          lifetime     #> 12 marti, jose          2027-06-11  temporary    #> 13 celaya lazama, pedro NA          lifetime     #> 14 ferrari, dr. michele NA          lifetime     #> 15 leinders, dr. geert  NA          lifetime     #> 16 korchemny, remi      NA          lifetime     #> 17 stewart, raymond     NA          lifetime     #> 18 graham, trevor       NA          lifetime"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-proh-assoc.html","id":"usada_proh_assoc","dir":"Articles","previous_headings":"","what":"usada_proh_assoc","title":"Scraping USADA prohibited associations","text":"resulting dataset named usada_proh_assoc exported inst/extdata/pro/","code":"usada_proh_assoc <- dplyr::rename(usada_prohib_assoc_pro,    suspend_end = suspension_ends_mm_dd_yyyy) |>    dplyr::mutate(suspend_type = dplyr::case_when(       stringr::str_detect(suspend_end, \"lifetime\") ~ \"lifetime\",       stringr::str_detect(suspend_end, \"indefinite*\") ~ \"indefinite*\",       TRUE ~ \"temporary\"),     suspend_end = dplyr::case_when(       stringr::str_detect(suspend_end, \"lifetime|indefinite*\") ~ NA_character_,       TRUE ~ suspend_end),     suspend_end = lubridate::mdy(suspend_end)) dplyr::glimpse(usada_proh_assoc) #> Rows: 18 #> Columns: 3 #> $ name         <chr> \"chavez, bernabe\", \"prempeh, ernest\", \"daniels, jamaal\", … #> $ suspend_end  <date> 2025-09-01, NA, 2025-07-26, NA, 2023-08-09, 2023-09-29, … #> $ suspend_type <chr> \"temporary\", \"indefinite*\", \"temporary\", \"lifetime\", \"tem…"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-proh-assoc.html","id":"export-raw-data","dir":"Articles","previous_headings":"","what":"Export raw data","title":"Scraping USADA prohibited associations","text":"’ll export raw data inst/extdata/raw/ folder. First create raw data folder today’s data: Create file paths .csv .rds files. look good, can run export functions: Verify:","code":"create_dir_date(dir_path = \"../inst/extdata/\", dir_name = \"raw/\") ✔ Creating folder: ../inst/extdata/raw/2023-01-20/ ✔ path is on clipboard! csv_pth <- paste0('../inst/extdata/raw/', Sys.Date(), '/',                    dtstamp(side = \"r\"), 'usada_prohib_assoc_raw.csv') csv_pth #> [1] \"../inst/extdata/raw/2023-01-20/2023-01-20-usada_prohib_assoc_raw.csv\" rds_pth <-  paste0('../inst/extdata/raw/', Sys.Date(), '/',                    dtstamp(side = \"r\"), 'usada_prohib_assoc_raw.rds') rds_pth #> [1] \"../inst/extdata/raw/2023-01-20/2023-01-20-usada_prohib_assoc_raw.rds\" readr::write_csv(x = usada_prohib_assoc_raw, file = csv_pth) readr::write_rds(x = usada_prohib_assoc_raw, file = rds_pth) fs::dir_tree(   path = paste0(\"../inst/extdata/raw/\", Sys.Date(), '/'),    regexp = \"assoc_raw\"   ) #> ../inst/extdata/raw/2023-01-20/ #> ├── 2023-01-20-usada_prohib_assoc_raw.csv #> └── 2023-01-20-usada_prohib_assoc_raw.rds"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-proh-assoc.html","id":"export-processed-data","dir":"Articles","previous_headings":"","what":"Export processed data","title":"Scraping USADA prohibited associations","text":"want export processed data separate folder (inst/extdata/<today>), can create using create_dir_date() Create export processed paths: Verify:","code":"create_dir_date(dir_path = \"../inst/extdata/\", dir_name = \"pro/\") ✔ Creating folder: ../inst/extdata/pro/2023-01-20/ ✔ path is on clipboard! csv_pth <- paste0('../inst/extdata/pro/',                         Sys.Date(),                         '/',                         dtstamp(side = \"r\"),                         'usada_proh_assoc_pro.csv') csv_pth #> [1] \"../inst/extdata/pro/2023-01-20/2023-01-20-usada_proh_assoc_pro.csv\" rds_pth <- paste0('../inst/extdata/pro/',                         Sys.Date(),                         '/',                         dtstamp(side = \"r\"),                         'usada_proh_assoc_pro.rds') rds_pth #> [1] \"../inst/extdata/pro/2023-01-20/2023-01-20-usada_proh_assoc_pro.rds\" readr::write_csv(x = usada_proh_assoc, file = csv_pth) readr::write_rds(x = usada_proh_assoc, file = rds_pth) fs::dir_tree(path = paste0(\"../inst/extdata/pro/\", Sys.Date(), '/'),    regexp = \"assoc_pro\") #> ../inst/extdata/pro/2023-01-20/ #> ├── 2023-01-20-usada_proh_assoc_pro.csv #> └── 2023-01-20-usada_proh_assoc_pro.rds"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-sanctions.html","id":"usada-sanction-data","dir":"Articles","previous_headings":"","what":"USADA sanction data","title":"Scraping USADA sanctions","text":"data ’ll downloading comes USADA sanctions table.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-sanctions.html","id":"use-your-manners","dir":"Articles","previous_headings":"","what":"Use your manners","title":"Scraping USADA sanctions","text":"package built top efforts fine people collected, organized, shared data, ’re going use polite package harvesting HTML tables. install package, run code : polite many options ethically scraping data (check package website information), ’ve chosen follow handy polite template:","code":"remotes::install_github(\"dmi3kno/polite\") library(polite) polite::use_manners()"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-sanctions.html","id":"check-robots-txt","dir":"Articles","previous_headings":"Use your manners","what":"Check robots.txt","title":"Scraping USADA sanctions","text":"’ll check robots.txt file scraping website: three paths TRUE, also check domain robotstxt::get_robotstxt(): can see Allow: / configuration gives us access download data.","code":"# retrieval rtxt <- robotstxt::robotstxt(domain = \"https://www.usada.org/\")  # printing rtxt$check(   # check permissions    paths = c(\"testing/\",              \"testing/results/\",              \"testing/results/sanctions/\"),   # bots   bot   = \"*\" ) #> [1] TRUE TRUE TRUE rt <- robotstxt::get_robotstxt(   domain = \"https://www.usada.org/testing/results/sanctions/\") # printing cat(rt[1]) #> # robots.txt overwrite by: on_suspect_content #>  #> User-agent: * #> Allow: /"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-sanctions.html","id":"scraping-with-polite-and-rvest","dir":"Articles","previous_headings":"Use your manners","what":"Scraping with polite and rvest","title":"Scraping USADA sanctions","text":"steps used scrape sanctions table: raw data look like? can also use scrape_usada_sanctions() function.","code":"usada_url = \"https://www.usada.org/testing/results/sanctions/\" usada_nodes <- polite::bow(usada_url) |>    polite::scrape() |>    rvest::html_nodes(\"table\")  usada_sanctions_raw <- rvest::html_table(usada_nodes[[1]]) dplyr::glimpse(usada_sanctions_raw) #> Rows: 895 #> Columns: 5 #> $ Athlete              <chr> \"Montañez Barroso, Elias\", \"Ruiz-Gutierrez, Nosle… #> $ Sport                <chr> \"Cycling\", \"Cycling\", \"Track and Field\", \"Cycling… #> $ `Substance/Reason`   <chr> \"Non-Analytical: Refusal to Submit to Sample Coll… #> $ `Sanction Terms`     <chr> \"4-Year Suspension; Loss of Results\", \"4-Year Sus… #> $ `Sanction Announced` <chr> \"01/10/2023\", \"01/04/2023\", \"12/08/2022\", \"12/05/…"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-sanctions.html","id":"process-text","dir":"Articles","previous_headings":"","what":"Process text","title":"Scraping USADA sanctions","text":"raw HTML table needs reformatting/restructuring can build visualizations models. ’ll start standardizing names making text lowercase. takes care column names case, invisible characters? (wait, invisible character???). cleaning text, can use process_text() function, adds steps: replaces carriage returns (\\\\r) newlines (\\\\n) white space converts variables text (chr) compare waldo::compare(), can see differences:","code":"usada_sanctions_lc <- janitor::clean_names(usada_sanctions_raw) |>                       purrr::map_df(.f = str_to_lower) glimpse(usada_sanctions_lc) #> Rows: 895 #> Columns: 5 #> $ athlete            <chr> \"montañez barroso, elias\", \"ruiz-gutierrez, noslen\"… #> $ sport              <chr> \"cycling\", \"cycling\", \"track and field\", \"cycling\",… #> $ substance_reason   <chr> \"non-analytical: refusal to submit to sample collec… #> $ sanction_terms     <chr> \"4-year suspension; loss of results\", \"4-year suspe… #> $ sanction_announced <chr> \"01/10/2023\", \"01/04/2023\", \"12/08/2022\", \"12/05/20… usada_sanctions_pro <- process_text(usada_sanctions_raw) dplyr::glimpse(usada_sanctions_pro) #> Rows: 895 #> Columns: 5 #> $ athlete            <chr> \"montañez barroso, elias\", \"ruiz-gutierrez, noslen\"… #> $ sport              <chr> \"cycling\", \"cycling\", \"track and field\", \"cycling\",… #> $ substance_reason   <chr> \"non-analytical: refusal to submit to sample collec… #> $ sanction_terms     <chr> \"4-year suspension; loss of results\", \"4-year suspe… #> $ sanction_announced <chr> \"01/10/2023\", \"01/04/2023\", \"12/08/2022\", \"12/05/20… waldo::compare(usada_sanctions_lc, usada_sanctions_pro) #> old vs new #>                                                                                                                                    sanction_terms #>   old[559, ] 18-month suspension - loss of results                                                                                                #>   old[560, ] public warning                                                                                                                       #>   old[561, ] 2-year suspension with 1 year reduction - loss of results                                                                            #> - old[562, ] 2-year suspension - loss of results;  #> 2-year suspension restarted - loss of results                                                 #> + new[562, ] 2-year suspension - loss of results;  2-year suspension restarted - loss of results                                                  #>   old[563, ] 18-month suspension - loss of results                                                                                                #>   old[564, ] 2-year suspension - loss of results; sanction tolled                                                                                 #>   old[565, ] 2-year suspension - loss of results                                                                                                  #>  #> old vs new #>                                                                                                                                    sanction_terms #>   old[672, ] 6-month suspension - loss of results                                                                                                 #>   old[673, ] 3-month suspension with 3-month deferral - loss of results                                                                           #>   old[674, ] 2-year suspension - loss of results                                                                                                  #> - old[675, ] 2-year suspension - loss of results  #> suspension extended 103 days                                                                   #> + new[675, ] 2-year suspension - loss of results  suspension extended 103 days                                                                    #>   old[676, ] 3-month suspension with 3-month deferral - loss of results                                                                           #>   old[677, ] 2-year suspension - loss of results                                                                                                  #>   old[678, ] 2-year suspension - loss of results                                                                                                  #>  #> lines(old$sanction_terms[[562]]) vs lines(new$sanction_terms[[562]]) #> - \"2-year suspension - loss of results; \" #> - \"2-year suspension restarted - loss of results\" #> + \"2-year suspension - loss of results;  2-year suspension restarted - loss of results\" #>  #> lines(old$sanction_terms[[675]]) vs lines(new$sanction_terms[[675]]) #> - \"2-year suspension - loss of results \" #> - \"suspension extended 103 days\" #> + \"2-year suspension - loss of results  suspension extended 103 days\""},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-sanctions.html","id":"export-raw-data","dir":"Articles","previous_headings":"","what":"Export raw data","title":"Scraping USADA sanctions","text":"’ll export raw data inst/extdata/raw/ folder. First create raw data folder today’s data: Create file paths .csv .rds files. look good, can run export functions: Verify:","code":"create_dir_date(dir_path = \"../inst/extdata/\", dir_name = \"raw/\") ✔ Creating folder: ../inst/extdata/raw/2023-01-20/ ✔ path is on clipboard! csv_pth <- paste0('../inst/extdata/raw/', Sys.Date(), '/',                    dtstamp(side = \"r\"), 'usada_sanctions_raw.csv') csv_pth #> [1] \"../inst/extdata/raw/2023-01-20/2023-01-20-usada_sanctions_raw.csv\" rds_pth <-  paste0('../inst/extdata/raw/', Sys.Date(), '/',                    dtstamp(side = \"r\"), 'usada_sanctions_raw.rds') rds_pth #> [1] \"../inst/extdata/raw/2023-01-20/2023-01-20-usada_sanctions_raw.rds\" readr::write_csv(x = usada_sanctions_raw, file = csv_pth) readr::write_rds(x = usada_sanctions_raw, file = rds_pth) fs::dir_tree(\"../inst/extdata/raw/\") #> ../inst/extdata/raw/ #> ├── 2023-01-19 #> │   ├── 2023-01-19-usada_prohib_assoc_raw.csv #> │   ├── 2023-01-19-usada_prohib_assoc_raw.rds #> │   ├── 2023-01-19-usada_sanctions_raw.csv #> │   └── 2023-01-19-usada_sanctions_raw.rds #> └── 2023-01-20 #>     ├── 2023-01-20-usada_prohib_assoc_raw.csv #>     ├── 2023-01-20-usada_prohib_assoc_raw.rds #>     ├── 2023-01-20-usada_sanctions_raw.csv #>     └── 2023-01-20-usada_sanctions_raw.rds"},{"path":"https://mjfrigaard.github.io/dopingdata/articles/scraping-usada-sanctions.html","id":"export-processed-data","dir":"Articles","previous_headings":"","what":"Export processed data","title":"Scraping USADA sanctions","text":"want export processed data separate folder (inst/extdata/<today>), can create using create_dir_date() Create export processed paths: Verify:","code":"create_dir_date(dir_path = \"../inst/extdata\", dir_name = \"pro/\") ✔ Creating folder: ../inst/extdata/pro/2023-01-20/ ✔ path is on clipboard! csv_pro_pth <- paste0('../inst/extdata/pro/',                         Sys.Date(),                         '/',                         dtstamp(side = \"r\"),                         'usada_sanctions_pro.csv') csv_pro_pth #> [1] \"../inst/extdata/pro/2023-01-20/2023-01-20-usada_sanctions_pro.csv\" rds_pro_pth <- paste0('../inst/extdata/pro/',                         Sys.Date(),                         '/',                         dtstamp(side = \"r\"),                         'usada_sanctions_pro.rds') rds_pro_pth #> [1] \"../inst/extdata/pro/2023-01-20/2023-01-20-usada_sanctions_pro.rds\" readr::write_csv(x = usada_sanctions_pro, file = csv_pro_pth) readr::write_rds(x = usada_sanctions_pro, file = rds_pro_pth) fs::dir_tree(path = paste0('../inst/extdata/pro/',                         Sys.Date(),                         '/'), regexp = \"sanctions_pro\") #> ../inst/extdata/pro/2023-01-20/ #> ├── 2023-01-20-usada_sanctions_pro.csv #> └── 2023-01-20-usada_sanctions_pro.rds"},{"path":"https://mjfrigaard.github.io/dopingdata/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Martin Frigaard. Maintainer, author.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Frigaard M (2023). dopingdata: USADA doping data. R package version 0.0.0.9000, https://mjfrigaard.github.io/dopingdata/.","code":"@Manual{,   title = {dopingdata: USADA doping data},   author = {Martin Frigaard},   year = {2023},   note = {R package version 0.0.0.9000},   url = {https://mjfrigaard.github.io/dopingdata/}, }"},{"path":"https://mjfrigaard.github.io/dopingdata/index.html","id":"dopingdata","dir":"","previous_headings":"","what":"USADA doping data ","title":"USADA doping data ","text":"goal dopingdata provide datasets United States Anti-Doping Agency exploration, modeling, visualizations. datasets package derived USADA website World Anti-Doping Agency (WADA) banned substances list.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"USADA doping data ","text":"can install development version dopingdata like :","code":"# install.packages(\"devtools\") devtools::install_github(\"mjfrigaard/dopingdata\")"},{"path":"https://mjfrigaard.github.io/dopingdata/index.html","id":"harvesting-data","dir":"","previous_headings":"","what":"Harvesting Data","title":"USADA doping data ","text":"dataset harvested using rvest xml2 packages, using manners (polite package). See Scraping USADA sanctions Scraping USADA prohibited associations vignettes information. raw data saved inst/extdata/raw folder. Raw datasets date (YYYY-MM-DD) prefix _raw suffix.","code":"#> inst/extdata/raw #> ├── 2023-01-19 #> │   ├── 2023-01-19-usada_prohib_assoc_raw.csv #> │   ├── 2023-01-19-usada_prohib_assoc_raw.rds #> │   ├── 2023-01-19-usada_sanctions_raw.csv #> │   └── 2023-01-19-usada_sanctions_raw.rds #> └── 2023-01-20 #>     ├── 2023-01-20-usada_prohib_assoc_raw.csv #>     ├── 2023-01-20-usada_prohib_assoc_raw.rds #>     ├── 2023-01-20-usada_sanctions_raw.csv #>     └── 2023-01-20-usada_sanctions_raw.rds"},{"path":"https://mjfrigaard.github.io/dopingdata/index.html","id":"processed-data","dir":"","previous_headings":"","what":"Processed Data","title":"USADA doping data ","text":"processed datasets created scraped raw data structured different purposes. cases, vignettes contain steps custom functions used harvest dataset. Processed datasets date (YYYY-MM-DD) prefix _pro suffix. Processed datasets dimensions structure _raw data, ’ve formatted easier wrangling/manipulation. Processed datasets inst/extdata/pro folder:","code":"#> inst/extdata/pro/ #> ├── 2023-01-19 #> │   ├── 2023-01-19-usada_proh_assoc_pro.csv #> │   ├── 2023-01-19-usada_proh_assoc_pro.rds #> │   ├── 2023-01-19-usada_sanctions_pro.csv #> │   └── 2023-01-19-usada_sanctions_pro.rds #> └── 2023-01-20 #>     ├── 2023-01-20-usada_proh_assoc_pro.csv #>     ├── 2023-01-20-usada_proh_assoc_pro.rds #>     ├── 2023-01-20-usada_sanctions_pro.csv #>     └── 2023-01-20-usada_sanctions_pro.rds"},{"path":"https://mjfrigaard.github.io/dopingdata/index.html","id":"derived-data","dir":"","previous_headings":"","what":"Derived Data","title":"USADA doping data ","text":"following datasets derived processed data: Sanction Dates Sports Substances (AAF) Non-Analytic Sanctions (ADRV) Sanction Terms Prohibited Associations Athletes derived datasets inst/extdata/der/ folder (date prefix suffixes).","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://mjfrigaard.github.io/dopingdata/index.html","id":"wada-data","dir":"","previous_headings":"","what":"WADA data","title":"USADA doping data ","text":"package also includes list World Anti-Doping Agency (WADA) banned substances (published online ).","code":"#> inst/extdata/wada/ #> ├── wada-2019-english-prohibited-list.xlsx #> └── wada_2019_english_prohibited_list.pdf"},{"path":"https://mjfrigaard.github.io/dopingdata/index.html","id":"more-wada-resources-on-banned-substances","dir":"","previous_headings":"WADA data","what":"More WADA Resources on banned substances","title":"USADA doping data ","text":"USADA - UFC","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/check_rtxt.html","id":null,"dir":"Reference","previous_headings":"","what":"Function for checking robots.txt file — check_rtxt","title":"Function for checking robots.txt file — check_rtxt","text":"Function checking robots.txt file","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/check_rtxt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function for checking robots.txt file — check_rtxt","text":"","code":"check_rtxt(url, delay, user_agent, force, verbose)"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/check_rtxt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function for checking robots.txt file — check_rtxt","text":"url web address download delay default delay user_agent user agent string force force re-downloading robots.xtx verbose logical","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/create_dir_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a folder (with date-stamped sub-folder) — create_dir_date","title":"Create a folder (with date-stamped sub-folder) — create_dir_date","text":"Create folder (date-stamped sub-folder)","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/create_dir_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a folder (with date-stamped sub-folder) — create_dir_date","text":"","code":"create_dir_date(dir_path = \"\", dir_name)"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/create_dir_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a folder (with date-stamped sub-folder) — create_dir_date","text":"dir_path parent folder dir_name directory name","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/create_dir_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a folder (with date-stamped sub-folder) — create_dir_date","text":"path folder","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/create_dir_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a folder (with date-stamped sub-folder) — create_dir_date","text":"","code":"create_dir_date(dir_name = \"tmp\") #> ✔ Creating folder: tmp/2023-01-20/ #> Error: Clipboard on X11 requires 'xclip' (recommended) or 'xsel'; Clipboard on Wayland requires 'wl-copy' and 'wl-paste'. create_dir_date(dir_path = \"tmp\", dir_name = \"doc\") #> ✔ Creating folder: tmp/doc/2023-01-20/ #> Error: Clipboard on X11 requires 'xclip' (recommended) or 'xsel'; Clipboard on Wayland requires 'wl-copy' and 'wl-paste'. create_dir_date(dir_path = \"tmp/x\", dir_name = \"doc\") #> ✔ Creating folder: tmp/x/doc/2023-01-20/ #> Error: Clipboard on X11 requires 'xclip' (recommended) or 'xsel'; Clipboard on Wayland requires 'wl-copy' and 'wl-paste'. create_dir_date(dir_path = \"tmp/x/\", dir_name = \"doc\") #> ✔ Creating folder: tmp/x/doc/2023-01-20/ #> Error: Clipboard on X11 requires 'xclip' (recommended) or 'xsel'; Clipboard on Wayland requires 'wl-copy' and 'wl-paste'."},{"path":"https://mjfrigaard.github.io/dopingdata/reference/create_regex_wb.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a regular expression with word boundaries — create_regex_wb","title":"Create a regular expression with word boundaries — create_regex_wb","text":"Create regular expression word boundaries","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/create_regex_wb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a regular expression with word boundaries — create_regex_wb","text":"","code":"create_regex_wb(string)"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/create_regex_wb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a regular expression with word boundaries — create_regex_wb","text":"string character vector items","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/create_regex_wb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a regular expression with word boundaries — create_regex_wb","text":"wb_regex regular expression","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/create_regex_wb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a regular expression with word boundaries — create_regex_wb","text":"","code":"require(stringr) #> Loading required package: stringr wb_regex <- create_regex_wb(c(\"pink\", \"salmon.\")) str_view_all(stringr::sentences, wb_regex, match = TRUE) #> Warning: `str_view()` was deprecated in stringr 1.5.0. #> ℹ Please use `str_view_all()` instead. #>  [12] │ A rod is used to catch <pink> <salmon>. #> [714] │ A <pink> shell was found on the sandy beach."},{"path":"https://mjfrigaard.github.io/dopingdata/reference/dtstamp.html","id":null,"dir":"Reference","previous_headings":"","what":"Insert date/time stamp — dtstamp","title":"Insert date/time stamp — dtstamp","text":"Insert date/time stamp","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/dtstamp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Insert date/time stamp — dtstamp","text":"","code":"dtstamp(include_time = FALSE, side = \"none\")"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/dtstamp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Insert date/time stamp — dtstamp","text":"include_time logical, include time? side include hyphen (-) 'left' 'right' side (default 'none')","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/dtstamp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Insert date/time stamp — dtstamp","text":"polished date (date time) stamp","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/dtstamp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Insert date/time stamp — dtstamp","text":"","code":"dtstamp(FALSE) #> [1] \"2023-01-20\" dtstamp() #> [1] \"2023-01-20\""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/get_recent_data_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Return current data in folder — get_recent_data_file","title":"Return current data in folder — get_recent_data_file","text":"Return current data folder","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/get_recent_data_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return current data in folder — get_recent_data_file","text":"","code":"get_recent_data_file(folder, type)"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/get_recent_data_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return current data in folder — get_recent_data_file","text":"folder directory data files type file extension","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/get_recent_data_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return current data in folder — get_recent_data_file","text":"path recent data file","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/get_recent_data_file.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return current data in folder — get_recent_data_file","text":"","code":"# not run get_recent_data_file(folder = \"inst/extdata/\", type = \"txt\") #> ! folder does not exist! #> Error in nrow(top_tbl): object 'top_tbl' not found get_recent_data_file(folder = \"inst/extdata/\", type = \"csv\") #> ! folder does not exist! #> Error in nrow(top_tbl): object 'top_tbl' not found get_recent_data_file(folder = \"inst/extdata/\", type = \"tsv\") #> ! folder does not exist! #> Error in nrow(top_tbl): object 'top_tbl' not found"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/get_recent_version.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the most recent modification time for folder and files — get_recent_version","title":"Return the most recent modification time for folder and files — get_recent_version","text":"Return recent modification time folder files","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/get_recent_version.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the most recent modification time for folder and files — get_recent_version","text":"","code":"get_recent_version(pth = \".\", full = FALSE)"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/get_recent_version.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the most recent modification time for folder and files — get_recent_version","text":"pth path file folder full return datetime (instead date)","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/get_recent_version.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the most recent modification time for folder and files — get_recent_version","text":"vrsn character vector date datetime","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/get_recent_version.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return the most recent modification time for folder and files — get_recent_version","text":"","code":"get_recent_version(\"wrong\") #> Loading required package: fs #> Loading required package: purrr #> Error in get_recent_version(\"wrong\"): Sorry--this is not a valid file path get_recent_version(\"inst/extdata/\") #> Error in get_recent_version(\"inst/extdata/\"): Sorry--this is not a valid file path get_recent_version(\"inst/extdata/raw\", full = TRUE) #> Error in get_recent_version(\"inst/extdata/raw\", full = TRUE): Sorry--this is not a valid file path"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/guess_basename.html","id":null,"dir":"Reference","previous_headings":"","what":"Guess filename for download from url — guess_basename","title":"Guess filename for download from url — guess_basename","text":"Guess filename download url","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/guess_basename.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Guess filename for download from url — guess_basename","text":"","code":"guess_basename(x)"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/guess_basename.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Guess filename for download from url — guess_basename","text":"x url guess filename ","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/nin.html","id":null,"dir":"Reference","previous_headings":"","what":"Not in (not-in operator for R.) — %nin%","title":"Not in (not-in operator for R.) — %nin%","text":"(-operator R.)","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/nin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Not in (not-in operator for R.) — %nin%","text":"","code":"x %nin% y"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/nin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Not in (not-in operator for R.) — %nin%","text":"x vector NULL: values matched. y vector NULL: values matched .","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/nin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Not in (not-in operator for R.) — %nin%","text":"negation %%.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/nin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Not in (not-in operator for R.) — %nin%","text":"","code":"1 %nin% 2:10 #> [1] TRUE c(\"a\", \"b\") %nin% c(\"a\", \"c\", \"d\") #> [1] FALSE  TRUE"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/otherwise.html","id":null,"dir":"Reference","previous_headings":"","what":"null-coalescing operator. See purrr for details. — %otherwise%","title":"null-coalescing operator. See purrr for details. — %otherwise%","text":"null-coalescing operator. See purrr details.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/otherwise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"null-coalescing operator. See purrr for details. — %otherwise%","text":"","code":"lhs %otherwise% rhs"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/otherwise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"null-coalescing operator. See purrr for details. — %otherwise%","text":"lhs left hand side rhs right hand side","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/polite_download_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Polite download — polite_download_file","title":"Polite download — polite_download_file","text":"Polite download","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/polite_download_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Polite download — polite_download_file","text":"","code":"polite_download_file(   url,   destfile = guess_basename(url),   ...,   quiet = !verbose,   mode = \"wb\",   path = \"downloads/\",   user_agent = paste0(\"polite \", getOption(\"HTTPUserAgent\")),   delay = 5,   force = FALSE,   overwrite = FALSE,   verbose = FALSE )"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/polite_download_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Polite download — polite_download_file","text":"url web address file downloaded destfile name destination file ... additional arguments passed `download.file` quiet default value inverse  `verbose` mode download mode. Default value \"wb\" path path save. Default path `downloads/` user_agent default value `paste0(\"polite \", getOption(\"HTTPUserAgent\"))` delay default value equal 5 force force re-download robots.txt overwrite overwrite downloaded file. Default value FALSE verbose default value FALSE","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/polite_fetch_rtxt.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to get robots.txt is structured form. Memoised — polite_fetch_rtxt","title":"Function to get robots.txt is structured form. Memoised — polite_fetch_rtxt","text":"Function get robots.txt structured form. Memoised","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/polite_fetch_rtxt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to get robots.txt is structured form. Memoised — polite_fetch_rtxt","text":"","code":"polite_fetch_rtxt(..., user_agent, delay, verbose)"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/polite_fetch_rtxt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to get robots.txt is structured form. Memoised — polite_fetch_rtxt","text":"... arguments passed `robotstxt::robotstxt()` user_agent user agent string delay default delay verbose logical","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/polite_read_html.html","id":null,"dir":"Reference","previous_headings":"","what":"function that actually fetches response from the web — polite_read_html","title":"function that actually fetches response from the web — polite_read_html","text":"function actually fetches response web","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/polite_read_html.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"function that actually fetches response from the web — polite_read_html","text":"","code":"polite_read_html(   url,   ...,   delay = 5,   user_agent = paste0(\"polite \", getOption(\"HTTPUserAgent\"), \"bot\"),   force = FALSE,   verbose = FALSE )"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/polite_read_html.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"function that actually fetches response from the web — polite_read_html","text":"url web address scraping ... arguments passed `httr::GET()` delay scraping delay. Default 5 sec user_agent user agent string. Default value `paste0(\"polite \", getOption(\"HTTPUserAgent\"), \"bot\")` force force re-download robots.txt verbose default FALSE","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/process_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Process raw data — process_text","title":"Process raw data — process_text","text":"Process raw data","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/process_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process raw data — process_text","text":"","code":"process_text(raw_data)"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/process_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process raw data — process_text","text":"raw_data","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/process_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process raw data — process_text","text":"tibble standardized names, lowercase text, character!","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/process_text.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process raw data — process_text","text":"","code":"require(palmerpenguins) #> Loading required package: palmerpenguins process_text(palmerpenguins::penguins_raw) #> # A tibble: 344 × 17 #>    study_n…¹ sampl…² species region island stage indiv…³ clutc…⁴ date_…⁵ culme…⁶ #>    <chr>     <chr>   <chr>   <chr>  <chr>  <chr> <chr>   <chr>   <chr>   <chr>   #>  1 pal0708   1       adelie… anvers torge… adul… n1a1    yes     2007-1… 39.1    #>  2 pal0708   2       adelie… anvers torge… adul… n1a2    yes     2007-1… 39.5    #>  3 pal0708   3       adelie… anvers torge… adul… n2a1    yes     2007-1… 40.3    #>  4 pal0708   4       adelie… anvers torge… adul… n2a2    yes     2007-1… NA      #>  5 pal0708   5       adelie… anvers torge… adul… n3a1    yes     2007-1… 36.7    #>  6 pal0708   6       adelie… anvers torge… adul… n3a2    yes     2007-1… 39.3    #>  7 pal0708   7       adelie… anvers torge… adul… n4a1    no      2007-1… 38.9    #>  8 pal0708   8       adelie… anvers torge… adul… n4a2    no      2007-1… 39.2    #>  9 pal0708   9       adelie… anvers torge… adul… n5a1    yes     2007-1… 34.1    #> 10 pal0708   10      adelie… anvers torge… adul… n5a2    yes     2007-1… 42      #> # … with 334 more rows, 7 more variables: culmen_depth_mm <chr>, #> #   flipper_length_mm <chr>, body_mass_g <chr>, sex <chr>, #> #   delta_15_n_o_oo <chr>, delta_13_c_o_oo <chr>, comments <chr>, and #> #   abbreviated variable names ¹​study_name, ²​sample_number, ³​individual_id, #> #   ⁴​clutch_completion, ⁵​date_egg, ⁶​culmen_length_mm"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/run_app.html","id":null,"dir":"Reference","previous_headings":"","what":"Run the Shiny Application — run_app","title":"Run the Shiny Application — run_app","text":"Run Shiny Application","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/run_app.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run the Shiny Application — run_app","text":"","code":"run_app(   onStart = NULL,   options = list(),   enableBookmarking = NULL,   uiPattern = \"/\",   ... )"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/run_app.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run the Shiny Application — run_app","text":"onStart function called app actually run. needed shinyAppObj, since shinyAppDir case, global.R file can used purpose. options Named options passed runApp call (can following: \"port\", \"launch.browser\", \"host\", \"quiet\", \"display.mode\" \"test.mode\"). can also specify width height parameters provide hint embedding environment ideal height/width app. enableBookmarking Can one \"url\", \"server\", \"disable\". default value, NULL, respect setting previous calls  enableBookmarking(). See enableBookmarking() information bookmarking app. uiPattern regular expression applied GET request determine whether ui used handle request. Note entire request path must match regular expression order match considered successful. ... arguments pass golem_opts. See `?golem::get_golem_options` details.","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/str_extract_matches.html","id":null,"dir":"Reference","previous_headings":"","what":"Match string and extract the matched value — str_extract_matches","title":"Match string and extract the matched value — str_extract_matches","text":"Match string extract matched value","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/str_extract_matches.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Match string and extract the matched value — str_extract_matches","text":"","code":"str_extract_matches(string, pattern)"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/str_extract_matches.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Match string and extract the matched value — str_extract_matches","text":"string string search pattern regex pattern match","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/str_extract_matches.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Match string and extract the matched value — str_extract_matches","text":"matched string","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/str_extract_matches.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Match string and extract the matched value — str_extract_matches","text":"","code":"require(dplyr) #> Loading required package: dplyr #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union require(tidyr) #> Loading required package: tidyr dplyr::mutate(dplyr::starwars,       match = str_extract_matches(name, \"Skywalker\")) |>   dplyr::select(last_col()) #> # A tibble: 87 × 1 #>    match     #>    <chr>     #>  1 Skywalker #>  2 NA        #>  3 NA        #>  4 NA        #>  5 NA        #>  6 NA        #>  7 NA        #>  8 NA        #>  9 NA        #> 10 NA        #> # … with 77 more rows"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/str_parse_term.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse string into individual terms (as tibble) — str_parse_term","title":"Parse string into individual terms (as tibble) — str_parse_term","text":"Parse string individual terms (tibble)","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/str_parse_term.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse string into individual terms (as tibble) — str_parse_term","text":"","code":"str_parse_term(term)"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/str_parse_term.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse string into individual terms (as tibble) — str_parse_term","text":"search_term","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/str_parse_term.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse string into individual terms (as tibble) — str_parse_term","text":"tibble unique terms term","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/str_parse_term.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parse string into individual terms (as tibble) — str_parse_term","text":"","code":"require(stringr) require(purrr) require(tibble) #> Loading required package: tibble str_parse_term(term = \"A large size in stockings is hard to sell.\") #> # A tibble: 9 × 2 #>   `Unique Items` Term                                       #>   <chr>          <chr>                                      #> 1 A              A large size in stockings is hard to sell. #> 2 large          NA                                         #> 3 size           NA                                         #> 4 in             NA                                         #> 5 stockings      NA                                         #> 6 is             NA                                         #> 7 hard           NA                                         #> 8 to             NA                                         #> 9 sell.          NA"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/theme_ggp2g.html","id":null,"dir":"Reference","previous_headings":"","what":"ggplot2 theme (doping data) — theme_ggp2g","title":"ggplot2 theme (doping data) — theme_ggp2g","text":"ggplot2 theme (doping data)","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/theme_ggp2g.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ggplot2 theme (doping data) — theme_ggp2g","text":"","code":"theme_ggp2g(   base_size = 11,   base_family = \"Ubuntu\",   base_line_size = base_size/22,   base_rect_size = base_size/22 )"},{"path":"https://mjfrigaard.github.io/dopingdata/reference/theme_ggp2g.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ggplot2 theme (doping data) — theme_ggp2g","text":"base_size size font base_family family font base_line_size size lines base graph base_rect_size size rectangle base graph","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/reference/theme_ggp2g.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ggplot2 theme (doping data) — theme_ggp2g","text":"ggplot object","code":""},{"path":"https://mjfrigaard.github.io/dopingdata/setup.html","id":null,"dir":"","previous_headings":"","what":"setup","title":"setup","text":"following commands used push initial package Github:","code":"git init git add -A git commit -m \"initial commit\" git remote add origin git@github.com:mjfrigaard/dopingdata.git git branch -M main git push -u origin main Enumerating objects: 230, done. Counting objects: 100% (230/230), done. Delta compression using up to 12 threads Compressing objects: 100% (224/224), done. Writing objects: 100% (230/230), 10.09 MiB | 2.42 MiB/s, done. Total 230 (delta 16), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (16/16), done. To github.com:mjfrigaard/dopingdata.git  * [new branch]      main -> main branch 'main' set up to track 'origin/main'."},{"path":"https://mjfrigaard.github.io/dopingdata/setup.html","id":"pkgdown-setup","dir":"","previous_headings":"","what":"pkgdown setup","title":"setup","text":"site built: deployed locally : file:///Users/mjfrigaard/projects/dopingdata/docs/index.html","code":"usethis::use_pkgdown() ✔ Setting active project to '/Users/mjfrigaard/projects/dopingdata' ✔ Adding '^_pkgdown\\\\.yml$', '^docs$', '^pkgdown$' to '.Rbuildignore' ✔ Adding 'docs' to '.gitignore' ✔ Writing '_pkgdown.yml' • Modify '_pkgdown.yml' pkgdown::build_site() -- Installing package into temporary library ----------------------------------------- == Building pkgdown site ======================================================= Reading from: '/Users/mjfrigaard/projects/dopingdata' Writing to:   '/Users/mjfrigaard/projects/dopingdata/docs' -- Initialising site ----------------------------------------------------------- Copying '../../Library/Caches/org.R-project.R/R/renv/cache/v5/R-4.2/x86_64-apple-darwin17.0/pkgdown/2.0.7/16fa15449c930bf3a7761d3c68f8abf9/pkgdown/BS5/assets/link.svg' to 'link.svg' Copying '../../Library/Caches/org.R-project.R/R/renv/cache/v5/R-4.2/x86_64-apple-darwin17.0/pkgdown/2.0.7/16fa15449c930bf3a7761d3c68f8abf9/pkgdown/BS5/assets/pkgdown.js' to 'pkgdown.js' -- Building home --------------------------------------------------------------- Writing 'authors.html' Reading 'CODE_OF_CONDUCT.md' Writing 'CODE_OF_CONDUCT.html' Reading '_setup.md' Writing '_setup.html' Reading 'LICENSE.md' Writing 'LICENSE.html' Writing 'LICENSE-text.html' Writing '404.html' -- Building function reference ------------------------------------------------- Writing 'reference/index.html' Reading 'man/check_rtxt.Rd' Writing 'reference/check_rtxt.html' Reading 'man/create_dir_date.Rd' Writing 'reference/create_dir_date.html' Reading 'man/create_regex_wb.Rd' Writing 'reference/create_regex_wb.html' Reading 'man/dtstamp.Rd' Writing 'reference/dtstamp.html' Reading 'man/get_recent_data_file.Rd' Writing 'reference/get_recent_data_file.html' Reading 'man/get_recent_version.Rd' Writing 'reference/get_recent_version.html' Reading 'man/guess_basename.Rd' Writing 'reference/guess_basename.html' Reading 'man/nin.Rd' Writing 'reference/nin.html' Reading 'man/otherwise.Rd' Writing 'reference/otherwise.html' Reading 'man/polite_download_file.Rd' Writing 'reference/polite_download_file.html' Reading 'man/polite_fetch_rtxt.Rd' Writing 'reference/polite_fetch_rtxt.html' Reading 'man/polite_read_html.Rd' Writing 'reference/polite_read_html.html' Reading 'man/process_text.Rd' Writing 'reference/process_text.html' Reading 'man/run_app.Rd' Writing 'reference/run_app.html' Reading 'man/str_extract_matches.Rd' Writing 'reference/str_extract_matches.html' Reading 'man/str_parse_term.Rd' Writing 'reference/str_parse_term.html' Reading 'man/theme_ggp2g.Rd' Writing 'reference/theme_ggp2g.html' -- Building articles ----------------------------------------------------------- Writing 'articles/index.html' Reading 'vignettes/sanction-aaf-substances.Rmd' Writing 'articles/sanction-aaf-substances.html' Reading 'vignettes/sanction-adrv-substances.Rmd' Writing 'articles/sanction-adrv-substances.html' Reading 'vignettes/sanction-dates.Rmd' Writing 'articles/sanction-dates.html' Reading 'vignettes/sanction-sports.Rmd' Writing 'articles/sanction-sports.html' Reading 'vignettes/scraping-usada-proh-assoc.Rmd' Writing 'articles/scraping-usada-proh-assoc.html' Reading 'vignettes/scraping-usada-sanctions.Rmd' Writing 'articles/scraping-usada-sanctions.html' -- Building news --------------------------------------------------------------- Writing 'news/index.html' Writing 'sitemap.xml' -- Building search index ------------------------------------------------------- == DONE ======================================================================== -- Previewing site ------------------------------------------------------------"},{"path":"https://mjfrigaard.github.io/dopingdata/setup.html","id":"deploying-using-github-pages","dir":"","previous_headings":"","what":"Deploying using github pages","title":"setup","text":"setup GitHub pages, run following: completes following tasks: Add spice package website! Now set branch gh-pages GitHub deploy docs/ folder.","code":"usethis::use_pkgdown_github_pages() Overwrite pre-existing file '_pkgdown.yml'?  1: Yeah 2: Nope 3: Not now  Selection: 1 ✔ Writing '_pkgdown.yml' • Modify '_pkgdown.yml' ✔ Initializing empty, orphan 'gh-pages' branch in GitHub repo 'mjfrigaard/dopingdata' ✔ GitHub Pages is publishing from: • URL: 'https://mjfrigaard.github.io/dopingdata/' • Branch: 'gh-pages' • Path: '/' ✔ Creating '.github/' ✔ Adding '^\\\\.github$' to '.Rbuildignore' ✔ Adding '*.html' to '.github/.gitignore' ✔ Creating '.github/workflows/' ✔ Saving 'r-lib/actions/examples/pkgdown.yaml@v2' to '.github/workflows/pkgdown.yaml' • Learn more at <https://github.com/r-lib/actions/blob/v2/examples/README.md>. ✔ Recording 'https://mjfrigaard.github.io/dopingdata/' as site's url in '_pkgdown.yml' ✔ Adding 'https://mjfrigaard.github.io/dopingdata/' to URL field in DESCRIPTION ✔ Setting 'https://mjfrigaard.github.io/dopingdata/' as homepage of GitHub repo 'mjfrigaard/dopingdata' url: https://mjfrigaard.github.io/dopingdata/ template:   bootstrap: 5   bootswatch: minty   theme: gruvbox-dark   bslib:     base_font:       google: Ubuntu Mono     heading_font:       google: Ubuntu"},{"path":"https://mjfrigaard.github.io/dopingdata/setup.html","id":"issues","dir":"","previous_headings":"","what":"Issues","title":"setup","text":"collection issues ’ve found using pkgdown gh-pages. ’m always somehow able get site deployed, takes extra effort! pkgdown build giving following error GitHub actions: might one following issues","code":"The deploy step encountered an error: The process '/usr/bin/git' failed with exit code 1 ❌"},{"path":"https://mjfrigaard.github.io/dopingdata/setup.html","id":"deployment-issues-with-git-lfs","dir":"","previous_headings":"","what":"Deployment issues with Git LFS","title":"setup","text":"Apparently might caused Git LFS (large file system), can either 1) remove following instructions , First check see lfs installed tracking files. nothing, ’re good go! 2) adding lfs actions/checkout step:","code":"git lfs ls-files git lfs uninstall Hooks for this repository have been removed. Global Git LFS configuration has been removed. # check files git lfs ls-files # remove files rm -rf .git/lfs # check files again git lfs ls-files steps:       - uses: actions/checkout@v3         with:           lfs: true"},{"path":"https://mjfrigaard.github.io/dopingdata/setup.html","id":"limited-github-actions-permissions","dir":"","previous_headings":"","what":"Limited Github Actions Permissions","title":"setup","text":"failed attempts pkgdown, noticed actions successful git push. can see new gh-pages branch checked : GitHub actions attempts push changes results following error: Change settings Settings > Actions > General: Workflow permissions bottom, Choose default permissions granted GITHUB_TOKEN running workflows repository. can specify granular permissions workflow using YAML… Workflows read write permissions repository scopes. https://github.com/ad-m/github-push-action/issues/96#issuecomment-1396347833","code":"/usr/bin/git checkout -B gh-pages origin/gh-pages Previous HEAD position was 287eac9 pkgdown build gh-pages Switched to a new branch 'gh-pages' branch 'gh-pages' set up to track 'origin/gh-pages'. Force-pushing changes... push --force ***github.com/mjfrigaard/dopingdata.git github-pages-deploy-action/8znmd9sst:gh-pages remote: Permission to mjfrigaard/dopingdata.git denied to github-actions[bot]. fatal: unable to access 'https://github.com/mjfrigaard/dopingdata.git/': The requested URL returned error: 403 Running post deployment cleanup jobs… 🗑️ Error: The deploy step encountered an error: The process '/usr/bin/git' failed with exit code 128 ❌ Notice: Deployment failed! ❌"},{"path":"https://mjfrigaard.github.io/dopingdata/setup.html","id":"updating","dir":"","previous_headings":"","what":"Updating","title":"setup","text":"Check post : deploy main, added .nojekyll file:","code":"git add -A # to see what changes are going to be committed git status  # commit changes git commit -m 'changes' # push git push origin main # go to the gh-pages branch git checkout gh-pages  # bring gh-pages up to date with main git rebase main # push the changes git push origin gh-pages  # return to the main branch git checkout main git branch --set-upstream-to=origin/<branch> gh-pages git branch --set-upstream-to=origin/main gh-pages touch .nojekyll"},{"path":"https://mjfrigaard.github.io/dopingdata/setup.html","id":"deploy-a-pkgdown-site-to-gh-pages-branch","dir":"","previous_headings":"","what":"Deploy a pkgdown site to gh-pages branch","title":"setup","text":"https://gist.github.com/AliciaSchep/f4287a4797d15d2b7923f12d5d9cc93d","code":"## Adapted from r-lib/pkgdown source code from RStudio https://github.com/r-lib/pkgdown  ## Helper functions, directly from pkgdown code -------------------------------- git <- function(...) {   processx::run(\"git\", c(...), echo_cmd = TRUE, echo = TRUE) }  github_clone <- function(dir, repo_slug) {   remote_url <- sprintf(\"git@github.com:%s.git\", repo_slug)   cli::rule(\"Cloning existing site\", line = 1)   git(\"clone\",       \"--single-branch\", \"-b\", \"gh-pages\",       \"--depth\", \"1\",       remote_url,       dir   ) }  github_push <- function(dir, commit_message) {   # force execution before changing working directory   force(commit_message)      cli::rule(\"Commiting updated site\", line = 1)      withr::with_dir(dir, {     git(\"add\", \"-A\", \".\")     git(\"commit\", \"--allow-empty\", \"-m\", commit_message)          cli::rule(\"Deploying to GitHub Pages\", line = 1)     git(\"remote\", \"-v\")     git(\"push\", \"--force\", \"origin\", \"HEAD:gh-pages\")   }) }  ## Deploy function, adapted from deploy_local ---------------------------------- deploy_site_github_local <- function(repo, preview = TRUE, delete_previous = FALSE, ...) {   # repo is the github repository, e.g. \"username/repo\"   # preview is to whether to first preview the site before pushing   # delete_previous is a flag to delete previous gh_pages branch content   # ... are additional parameters to build_site   dest_dir <- fs::dir_create(fs::file_temp())   on.exit(fs::dir_delete(dest_dir))      github_clone(dest_dir, repo)   if (delete_previous) {     # This may be necessary if the branch has stuff not built by pkgdown     fs::dir_map(dest_dir, fs::file_delete)   }   pkgdown::build_site(\".\",              override = list(destination = dest_dir),              document = FALSE,              preview = FALSE,              ...   )      if (preview) {     browseURL(fs::path(dest_dir, \"index.html\"))     push <- utils::menu(c(\"Yes\",\"No\"), title = \"Push site?\") == 1   } else {     push <- TRUE   }      if (push) {     github_push(dest_dir, \"Building new version of pkgdown website\")   }      invisible() }"},{"path":"https://mjfrigaard.github.io/dopingdata/news/index.html","id":"dopingdata-0009000","dir":"Changelog","previous_headings":"","what":"dopingdata 0.0.0.9000","title":"dopingdata 0.0.0.9000","text":"Added NEWS.md file track changes package. Pushed site gh-pages branch using pkgdown (see _setup.md info). Add vignettes: sanction-dates sanction-sports sanction-aaf-substances sanction-adrv-substances","code":""}]
